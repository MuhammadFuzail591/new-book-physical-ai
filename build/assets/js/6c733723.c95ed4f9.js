"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[2987],{1292:(t,i,e)=>{e.r(i),e.d(i,{assets:()=>s,contentTitle:()=>n,default:()=>h,frontMatter:()=>c,metadata:()=>r,toc:()=>p});var o=e(4848),a=e(8453);const c={},n=void 0,r={id:"physical-ai/voice-robotics/chapter-summary",title:"chapter-summary",description:"",source:"@site/docs/physical-ai/voice-robotics/chapter-summary.mdx",sourceDirName:"physical-ai/voice-robotics",slug:"/physical-ai/voice-robotics/chapter-summary",permalink:"/physical-ai-textbook/physical-ai/physical-ai/voice-robotics/chapter-summary",draft:!1,unlisted:!1,editUrl:"https://github.com/your-username/physical-ai-textbook/tree/main/docs/physical-ai/voice-robotics/chapter-summary.mdx",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Voice-to-Action Command Processing in Robotics",permalink:"/physical-ai-textbook/physical-ai/physical-ai/voice-robotics/voice-to-action"},next:{title:"Chapter 13 - Cognitive Planning with Vision-Language-Action Systems",permalink:"/physical-ai-textbook/physical-ai/physical-ai/cognitive-planning/"}},s={},p=[];function l(t){const i={p:"p",...(0,a.R)(),...t.components};return(0,o.jsx)(i.p,{children:"---\\ntitle: Chapter Placeholder - Voice Robotics Chapter Summary\\n---\\n\\n# Chapter Summary\\n\\nSummary of the voice robotics chapter."})}function h(t={}){const{wrapper:i}={...(0,a.R)(),...t.components};return i?(0,o.jsx)(i,{...t,children:(0,o.jsx)(l,{...t})}):l(t)}},8453:(t,i,e)=>{e.d(i,{R:()=>n,x:()=>r});var o=e(6540);const a={},c=o.createContext(a);function n(t){const i=o.useContext(c);return o.useMemo(function(){return"function"==typeof t?t(i):{...i,...t}},[i,t])}function r(t){let i;return i=t.disableParentContext?"function"==typeof t.components?t.components(a):t.components||a:n(t.components),o.createElement(c.Provider,{value:i},t.children)}}}]);