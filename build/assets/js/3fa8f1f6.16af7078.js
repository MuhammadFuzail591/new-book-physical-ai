"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[8724],{549:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>t,default:()=>p,frontMatter:()=>r,metadata:()=>o,toc:()=>d});var i=a(4848),s=a(8453);const r={title:"Sim-to-Real Transfer Techniques in Robotics"},t="Sim-to-Real Transfer Techniques",o={id:"navigation-systems/sim-to-real",title:"Sim-to-Real Transfer Techniques in Robotics",description:"Introduction to Sim-to-Real Transfer",source:"@site/docs/physical-ai/navigation-systems/03-sim-to-real.mdx",sourceDirName:"navigation-systems",slug:"/navigation-systems/sim-to-real",permalink:"/navigation-systems/sim-to-real",draft:!1,unlisted:!1,editUrl:"https://github.com/MuhammadFuzail591/new-book-physical-ai/tree/main/docs/physical-ai/navigation-systems/03-sim-to-real.mdx",tags:[],version:"current",sidebarPosition:3,frontMatter:{title:"Sim-to-Real Transfer Techniques in Robotics"},sidebar:"tutorialSidebar",previous:{title:"Chapter 11 - Navigation Systems for Physical AI",permalink:"/navigation-systems/navigation"},next:{title:"Chapter 12 - Voice-to-Action Robotics with Whisper & ROS 2",permalink:"/voice-robotics/"}},l={},d=[{value:"Introduction to Sim-to-Real Transfer",id:"introduction-to-sim-to-real-transfer",level:2},{value:"Domain Randomization",id:"domain-randomization",level:2},{value:"Visual Domain Randomization",id:"visual-domain-randomization",level:3},{value:"Physical Domain Randomization",id:"physical-domain-randomization",level:3},{value:"System Identification",id:"system-identification",level:2},{value:"Black-Box System Identification",id:"black-box-system-identification",level:3},{value:"Grey-Box System Identification",id:"grey-box-system-identification",level:3},{value:"Sensor Noise Modeling",id:"sensor-noise-modeling",level:2},{value:"Reality Gap Mitigation Strategies",id:"reality-gap-mitigation-strategies",level:2},{value:"Progressive Domain Randomization",id:"progressive-domain-randomization",level:3},{value:"Domain Adaptation with Adversarial Training",id:"domain-adaptation-with-adversarial-training",level:3},{value:"Practical Implementation Guidelines",id:"practical-implementation-guidelines",level:2},{value:"Sim-to-Real Transfer Pipeline",id:"sim-to-real-transfer-pipeline",level:3},{value:"Evaluation Metrics for Sim-to-Real Transfer",id:"evaluation-metrics-for-sim-to-real-transfer",level:2},{value:"Best Practices and Considerations",id:"best-practices-and-considerations",level:2}];function m(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h1,{id:"sim-to-real-transfer-techniques",children:"Sim-to-Real Transfer Techniques"}),"\n",(0,i.jsx)(e.h2,{id:"introduction-to-sim-to-real-transfer",children:"Introduction to Sim-to-Real Transfer"}),"\n",(0,i.jsx)(e.p,{children:'Sim-to-real transfer, also known as domain transfer, refers to the process of transferring policies, controllers, or learning algorithms developed in simulation environments to real-world robotic systems. This critical aspect of robotics research addresses the "reality gap" - the discrepancy between simulated and real environments that can cause policies trained in simulation to fail when deployed on physical robots.'}),"\n",(0,i.jsx)(e.p,{children:"The reality gap encompasses various factors including:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Visual differences (textures, lighting, shadows)"}),"\n",(0,i.jsx)(e.li,{children:"Physical properties (friction, dynamics, actuator behavior)"}),"\n",(0,i.jsx)(e.li,{children:"Sensor noise and calibration differences"}),"\n",(0,i.jsx)(e.li,{children:"Environmental uncertainties and disturbances"}),"\n",(0,i.jsx)(e.li,{children:"Model inaccuracies in simulation"}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"Successfully bridging this gap is essential for deploying robotics solutions at scale, as real-world training is often expensive, time-consuming, and potentially dangerous."}),"\n",(0,i.jsx)(e.h2,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,i.jsx)(e.p,{children:"Domain randomization is a technique that involves randomizing simulation parameters during training to improve policy robustness. The approach trains policies on a wide variety of simulation conditions, making them more adaptable to real-world variations."}),"\n",(0,i.jsx)(e.h3,{id:"visual-domain-randomization",children:"Visual Domain Randomization"}),"\n",(0,i.jsx)(e.p,{children:"Visual domain randomization focuses on randomizing visual properties in simulation:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport cv2\nfrom dataclasses import dataclass\nfrom typing import Tuple, Optional\n\n@dataclass\nclass DomainRandomizationParams:\n    """Parameters for domain randomization in simulation"""\n    lighting_range: Tuple[float, float] = (0.5, 2.0)  # Lighting intensity range\n    color_variance: float = 0.2  # Color variation factor\n    texture_randomization: bool = True\n    shadow_randomization: bool = True\n    noise_range: Tuple[float, float] = (0.0, 0.05)  # Noise level range\n    blur_range: Tuple[float, float] = (0.0, 1.0)  # Blur kernel size range\n\nclass VisualDomainRandomizer:\n    """Applies visual domain randomization to simulated images"""\n\n    def __init__(self, params: DomainRandomizationParams):\n        self.params = params\n\n    def randomize_image(self, image: np.ndarray) -> np.ndarray:\n        """Apply randomization transformations to an image"""\n        # Randomize lighting\n        lighting_factor = np.random.uniform(\n            self.params.lighting_range[0],\n            self.params.lighting_range[1]\n        )\n        randomized = np.clip(image.astype(np.float32) * lighting_factor, 0, 255).astype(np.uint8)\n\n        # Add random noise\n        noise_level = np.random.uniform(\n            self.params.noise_range[0],\n            self.params.noise_range[1]\n        )\n        noise = np.random.normal(0, noise_level * 255, image.shape).astype(np.uint8)\n        randomized = cv2.add(randomized, noise)\n\n        # Apply random blur\n        blur_kernel = np.random.uniform(\n            self.params.blur_range[0],\n            self.params.blur_range[1]\n        )\n        if blur_kernel > 0:\n            kernel_size = int(2 * np.floor(blur_kernel) + 1)\n            if kernel_size > 1:\n                randomized = cv2.GaussianBlur(randomized, (kernel_size, kernel_size), blur_kernel)\n\n        # Randomize colors\n        color_shift = np.random.uniform(-self.params.color_variance, self.params.color_variance, 3)\n        randomized = randomized.astype(np.float32)\n        randomized[:, :, 0] = np.clip(randomized[:, :, 0] * (1 + color_shift[0]), 0, 255)\n        randomized[:, :, 1] = np.clip(randomized[:, :, 1] * (1 + color_shift[1]), 0, 255)\n        randomized[:, :, 2] = np.clip(randomized[:, :, 2] * (1 + color_shift[2]), 0, 255)\n\n        return randomized.astype(np.uint8)\n'})}),"\n",(0,i.jsx)(e.h3,{id:"physical-domain-randomization",children:"Physical Domain Randomization"}),"\n",(0,i.jsx)(e.p,{children:"Physical domain randomization involves randomizing physical parameters such as friction coefficients, mass, and actuator dynamics:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom dataclasses import dataclass\nfrom typing import Dict, Any\n\n@dataclass\nclass PhysicalDomainParams:\n    \"\"\"Parameters for physical domain randomization\"\"\"\n    mass_range: Tuple[float, float] = (0.8, 1.2)  # Mass multiplier range\n    friction_range: Tuple[float, float] = (0.5, 2.0)  # Friction multiplier range\n    damping_range: Tuple[float, float] = (0.8, 1.2)  # Damping multiplier range\n    actuator_noise_range: Tuple[float, float] = (0.0, 0.05)  # Actuator noise level\n    sensor_noise_range: Tuple[float, float] = (0.0, 0.02)  # Sensor noise level\n    com_offset_range: Tuple[float, float] = (-0.01, 0.01)  # Center of mass offset\n\nclass PhysicalDomainRandomizer:\n    \"\"\"Applies physical domain randomization to robot parameters\"\"\"\n\n    def __init__(self, params: PhysicalDomainParams):\n        self.params = params\n        self.randomized_params = {}\n\n    def randomize_robot_parameters(self, base_params: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Randomize physical parameters for a robot\"\"\"\n        randomized = base_params.copy()\n\n        # Randomize mass\n        mass_multiplier = np.random.uniform(\n            self.params.mass_range[0],\n            self.params.mass_range[1]\n        )\n        for link_name, mass in randomized.get('masses', {}).items():\n            randomized['masses'][link_name] = mass * mass_multiplier\n\n        # Randomize friction\n        friction_multiplier = np.random.uniform(\n            self.params.friction_range[0],\n            self.params.friction_range[1]\n        )\n        for joint_name, friction in randomized.get('friction', {}).items():\n            randomized['friction'][joint_name] = friction * friction_multiplier\n\n        # Randomize damping\n        damping_multiplier = np.random.uniform(\n            self.params.damping_range[0],\n            self.params.damping_range[1]\n        )\n        for joint_name, damping in randomized.get('damping', {}).items():\n            randomized['damping'][joint_name] = damping * damping_multiplier\n\n        # Add actuator noise characteristics\n        actuator_noise = np.random.uniform(\n            self.params.actuator_noise_range[0],\n            self.params.actuator_noise_range[1]\n        )\n        randomized['actuator_noise'] = actuator_noise\n\n        # Add sensor noise characteristics\n        sensor_noise = np.random.uniform(\n            self.params.sensor_noise_range[0],\n            self.params.sensor_noise_range[1]\n        )\n        randomized['sensor_noise'] = sensor_noise\n\n        # Randomize center of mass offsets\n        for link_name in randomized.get('links', []):\n            com_offset = np.random.uniform(\n                self.params.com_offset_range[0],\n                self.params.com_offset_range[1],\n                3\n            )\n            randomized['com_offsets'][link_name] = com_offset\n\n        return randomized\n"})}),"\n",(0,i.jsx)(e.h2,{id:"system-identification",children:"System Identification"}),"\n",(0,i.jsx)(e.p,{children:"System identification is the process of developing mathematical models of dynamic systems from measured input-output data. In robotics, this technique helps create more accurate models that better match real-world behavior."}),"\n",(0,i.jsx)(e.h3,{id:"black-box-system-identification",children:"Black-Box System Identification"}),"\n",(0,i.jsx)(e.p,{children:"Black-box identification involves fitting models without detailed knowledge of the underlying physics:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom scipy.optimize import minimize\nfrom typing import List, Tuple, Callable\n\nclass BlackBoxSystemIdentifier:\n    """Identifies system parameters using black-box methods"""\n\n    def __init__(self, model_order: int = 4):\n        self.model_order = model_order\n        self.parameters = None\n\n    def arx_model(self, u: np.ndarray, y: np.ndarray, na: int, nb: int) -> np.ndarray:\n        """\n        ARX (AutoRegressive with eXogenous inputs) model\n        y(t) + a1*y(t-1) + ... + ana*y(t-na) = b1*u(t-1) + ... + bnb*u(t-nb)\n        """\n        n_samples = len(u)\n        n_params = na + nb\n\n        # Build regression matrix\n        Phi = np.zeros((n_samples - max(na, nb), n_params))\n\n        for i in range(max(na, nb), n_samples):\n            row_idx = i - max(na, nb)\n\n            # Add past outputs\n            for j in range(na):\n                Phi[row_idx, j] = -y[i - j - 1]\n\n            # Add past inputs\n            for j in range(nb):\n                Phi[row_idx, na + j] = u[i - j - 1]\n\n        # Solve for parameters using least squares\n        Y = y[max(na, nb):]\n        params = np.linalg.lstsq(Phi, Y, rcond=None)[0]\n\n        return params\n\n    def identify_system(self, input_data: np.ndarray, output_data: np.ndarray) -> np.ndarray:\n        """Identify system parameters using ARX model"""\n        self.parameters = self.arx_model(\n            input_data,\n            output_data,\n            self.model_order,\n            self.model_order\n        )\n        return self.parameters\n\n    def simulate_system(self, input_sequence: np.ndarray, initial_state: np.ndarray = None) -> np.ndarray:\n        """Simulate the identified system"""\n        if self.parameters is None:\n            raise ValueError("System must be identified first")\n\n        na = self.model_order\n        nb = self.model_order\n\n        output = np.zeros(len(input_sequence))\n\n        if initial_state is not None:\n            # Initialize with provided initial state\n            for i in range(min(len(initial_state), na)):\n                if i < len(output):\n                    output[i] = initial_state[i]\n\n        for t in range(max(na, nb), len(input_sequence)):\n            # Calculate output based on ARX model\n            output[t] = 0\n\n            # Add contribution from past outputs\n            for i in range(na):\n                if t - i - 1 >= 0:\n                    output[t] += -self.parameters[i] * output[t - i - 1]\n\n            # Add contribution from past inputs\n            for i in range(nb):\n                if t - i - 1 >= 0:\n                    output[t] += self.parameters[na + i] * input_sequence[t - i - 1]\n\n        return output\n'})}),"\n",(0,i.jsx)(e.h3,{id:"grey-box-system-identification",children:"Grey-Box System Identification"}),"\n",(0,i.jsx)(e.p,{children:"Grey-box identification incorporates partial knowledge of the system structure:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom scipy.optimize import minimize\nfrom typing import Dict, Any\n\nclass GreyBoxSystemIdentifier:\n    """Identifies system parameters using grey-box methods"""\n\n    def __init__(self, robot_model: Dict[str, Any]):\n        self.robot_model = robot_model\n        self.identified_params = {}\n\n    def dynamics_model_error(self, params: np.ndarray, input_data: np.ndarray,\n                           output_data: np.ndarray) -> float:\n        """Calculate error between model prediction and actual data"""\n        # Update model with current parameters\n        self.update_model_parameters(params)\n\n        # Simulate model with input data\n        simulated_output = self.simulate_robot_dynamics(input_data)\n\n        # Calculate error\n        error = np.mean((simulated_output - output_data) ** 2)\n        return error\n\n    def update_model_parameters(self, params: np.ndarray):\n        """Update robot model parameters with identified values"""\n        # This would update the robot model with the current parameter set\n        # For example, updating masses, inertias, friction coefficients, etc.\n        param_idx = 0\n\n        # Update link masses\n        for link_name in self.robot_model.get(\'links\', []):\n            if f\'{link_name}_mass\' in self.robot_model:\n                self.robot_model[f\'{link_name}_mass\'] = params[param_idx]\n                param_idx += 1\n\n        # Update joint friction coefficients\n        for joint_name in self.robot_model.get(\'joints\', []):\n            if f\'{joint_name}_friction\' in self.robot_model:\n                self.robot_model[f\'{joint_name}_friction\'] = params[param_idx]\n                param_idx += 1\n\n        # Update other parameters as needed\n        # (inertias, damping, etc.)\n\n    def simulate_robot_dynamics(self, input_sequence: np.ndarray) -> np.ndarray:\n        """Simulate robot dynamics with current model parameters"""\n        # This would use the robot model to simulate dynamics\n        # For simplicity, returning a placeholder implementation\n        return np.zeros_like(input_sequence)\n\n    def identify_parameters(self, input_data: np.ndarray,\n                          output_data: np.ndarray) -> Dict[str, Any]:\n        """Identify system parameters using optimization"""\n        # Define initial parameter guesses\n        n_params = len(self.get_parameter_names())\n        initial_params = np.ones(n_params)  # Initial guess\n\n        # Optimize parameters to minimize error\n        result = minimize(\n            self.dynamics_model_error,\n            initial_params,\n            args=(input_data, output_data),\n            method=\'BFGS\'\n        )\n\n        # Store identified parameters\n        param_names = self.get_parameter_names()\n        self.identified_params = {\n            name: result.x[i] for i, name in enumerate(param_names)\n        }\n\n        return self.identified_params\n\n    def get_parameter_names(self) -> List[str]:\n        """Get names of parameters to be identified"""\n        names = []\n\n        # Add link mass parameters\n        for link_name in self.robot_model.get(\'links\', []):\n            if f\'{link_name}_mass\' in self.robot_model:\n                names.append(f\'{link_name}_mass\')\n\n        # Add joint friction parameters\n        for joint_name in self.robot_model.get(\'joints\', []):\n            if f\'{joint_name}_friction\' in self.robot_model:\n                names.append(f\'{joint_name}_friction\')\n\n        return names\n'})}),"\n",(0,i.jsx)(e.h2,{id:"sensor-noise-modeling",children:"Sensor Noise Modeling"}),"\n",(0,i.jsx)(e.p,{children:"Real sensors exhibit various types of noise that must be modeled in simulation for effective sim-to-real transfer:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom typing import Tuple\nimport random\n\nclass SensorNoiseModel:\n    """Models various types of sensor noise for sim-to-real transfer"""\n\n    def __init__(self):\n        self.noise_params = {}\n\n    def add_gaussian_noise(self, signal: np.ndarray, std_dev: float) -> np.ndarray:\n        """Add Gaussian (white) noise to a signal"""\n        noise = np.random.normal(0, std_dev, signal.shape)\n        return signal + noise\n\n    def add_bias_drift(self, signal: np.ndarray, drift_rate: float,\n                      initial_bias: float = 0.0) -> np.ndarray:\n        """Add slowly varying bias to a signal"""\n        time_steps = len(signal)\n        bias = initial_bias\n        drifted_signal = signal.copy()\n\n        for i in range(time_steps):\n            bias += np.random.normal(0, drift_rate)\n            drifted_signal[i] += bias\n\n        return drifted_signal\n\n    def add_quantization_noise(self, signal: np.ndarray, resolution: float) -> np.ndarray:\n        """Add quantization noise based on sensor resolution"""\n        quantized = np.round(signal / resolution) * resolution\n        return quantized\n\n    def add_delay(self, signal: np.ndarray, delay_steps: int) -> np.ndarray:\n        """Add delay to a signal"""\n        delayed = np.zeros_like(signal)\n        if delay_steps < len(signal):\n            delayed[delay_steps:] = signal[:-delay_steps]\n        else:\n            delayed[:] = signal[0]  # Hold first value if delay is too large\n        return delayed\n\n    def model_lidar_noise(self, distances: np.ndarray,\n                         base_std: float = 0.01) -> np.ndarray:\n        """Model LiDAR sensor noise (typically increases with distance)"""\n        # LiDAR noise typically increases with distance\n        distance_based_std = base_std * (1 + 0.1 * distances)\n        noise = np.random.normal(0, distance_based_std, distances.shape)\n        noisy_distances = distances + noise\n        # Ensure non-negative distances\n        return np.maximum(noisy_distances, 0.01)\n\n    def model_camera_noise(self, image: np.ndarray,\n                          noise_params: Dict[str, float]) -> np.ndarray:\n        """Model camera sensor noise including various effects"""\n        noisy_image = image.astype(np.float32)\n\n        # Add Gaussian noise\n        gaussian_noise = np.random.normal(\n            0, noise_params.get(\'gaussian_std\', 0.01), image.shape\n        )\n        noisy_image += gaussian_noise\n\n        # Add Poisson noise (shot noise)\n        poisson_noise = np.random.poisson(noisy_image) - noisy_image\n        noisy_image += poisson_noise * noise_params.get(\'poisson_factor\', 0.1)\n\n        # Add salt and pepper noise\n        salt_pepper_prob = noise_params.get(\'salt_pepper_prob\', 0.001)\n        salt_pepper_mask = np.random.random(image.shape[:2]) < salt_pepper_prob\n        noisy_image[salt_pepper_mask] = 255  # Salt\n        noisy_image[np.random.random(image.shape[:2]) < salt_pepper_prob] = 0  # Pepper\n\n        # Clip values to valid range\n        noisy_image = np.clip(noisy_image, 0, 255)\n\n        return noisy_image.astype(np.uint8)\n\n    def model_imu_noise(self, acceleration: np.ndarray, angular_velocity: np.ndarray,\n                       noise_params: Dict[str, float]) -> Tuple[np.ndarray, np.ndarray]:\n        """Model IMU sensor noise"""\n        # Accelerometer noise\n        acc_noise_std = noise_params.get(\'accelerometer_noise_std\', 0.01)\n        acc_bias_std = noise_params.get(\'accelerometer_bias_std\', 0.001)\n\n        noisy_acc = acceleration + np.random.normal(0, acc_noise_std, acceleration.shape)\n        acc_bias = np.random.normal(0, acc_bias_std, acceleration.shape)\n        noisy_acc += acc_bias\n\n        # Gyroscope noise\n        gyro_noise_std = noise_params.get(\'gyroscope_noise_std\', 0.001)\n        gyro_bias_std = noise_params.get(\'gyroscope_bias_std\', 0.0001)\n\n        noisy_gyro = angular_velocity + np.random.normal(0, gyro_noise_std, angular_velocity.shape)\n        gyro_bias = np.random.normal(0, gyro_bias_std, angular_velocity.shape)\n        noisy_gyro += gyro_bias\n\n        return noisy_acc, noisy_gyro\n'})}),"\n",(0,i.jsx)(e.h2,{id:"reality-gap-mitigation-strategies",children:"Reality Gap Mitigation Strategies"}),"\n",(0,i.jsx)(e.h3,{id:"progressive-domain-randomization",children:"Progressive Domain Randomization"}),"\n",(0,i.jsx)(e.p,{children:"Progressive domain randomization gradually increases the randomization range during training:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class ProgressiveDomainRandomizer:\n    """Applies progressive domain randomization during training"""\n\n    def __init__(self, initial_params: DomainRandomizationParams,\n                 final_params: DomainRandomizationParams,\n                 total_steps: int):\n        self.initial_params = initial_params\n        self.final_params = final_params\n        self.total_steps = total_steps\n        self.current_step = 0\n\n    def get_current_params(self) -> DomainRandomizationParams:\n        """Get domain randomization parameters for current training step"""\n        progress = min(self.current_step / self.total_steps, 1.0)\n\n        # Interpolate between initial and final parameters\n        lighting_range = self.interpolate_range(\n            self.initial_params.lighting_range,\n            self.final_params.lighting_range,\n            progress\n        )\n\n        color_variance = (\n            self.initial_params.color_variance +\n            progress * (self.final_params.color_variance - self.initial_params.color_variance)\n        )\n\n        noise_range = self.interpolate_range(\n            self.initial_params.noise_range,\n            self.final_params.noise_range,\n            progress\n        )\n\n        blur_range = self.interpolate_range(\n            self.initial_params.blur_range,\n            self.final_params.blur_range,\n            progress\n        )\n\n        return DomainRandomizationParams(\n            lighting_range=lighting_range,\n            color_variance=color_variance,\n            texture_randomization=self.final_params.texture_randomization,\n            shadow_randomization=self.final_params.shadow_randomization,\n            noise_range=noise_range,\n            blur_range=blur_range\n        )\n\n    def interpolate_range(self, initial_range: Tuple[float, float],\n                         final_range: Tuple[float, float],\n                         progress: float) -> Tuple[float, float]:\n        """Interpolate between two ranges"""\n        start = initial_range[0] + progress * (final_range[0] - initial_range[0])\n        end = initial_range[1] + progress * (final_range[1] - initial_range[1])\n        return (start, end)\n\n    def update_step(self):\n        """Increment training step"""\n        self.current_step += 1\n'})}),"\n",(0,i.jsx)(e.h3,{id:"domain-adaptation-with-adversarial-training",children:"Domain Adaptation with Adversarial Training"}),"\n",(0,i.jsx)(e.p,{children:"Adversarial domain adaptation uses a discriminator to distinguish between real and simulated data:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom typing import Tuple, Optional\n\nclass AdversarialDomainAdapter:\n    """Implements adversarial domain adaptation for sim-to-real transfer"""\n\n    def __init__(self, feature_dim: int, learning_rate: float = 0.001):\n        # Initialize discriminator weights\n        self.discriminator_weights = np.random.normal(0, 0.1, feature_dim)\n        self.feature_extractor_weights = np.random.normal(0, 0.1, feature_dim)\n        self.learning_rate = learning_rate\n        self.discriminator_optim = {\'momentum\': 0.9, \'velocity\': np.zeros_like(self.discriminator_weights)}\n        self.feature_optim = {\'momentum\': 0.9, \'velocity\': np.zeros_like(self.feature_extractor_weights)}\n\n    def discriminator_forward(self, features: np.ndarray) -> np.ndarray:\n        """Forward pass through discriminator"""\n        logits = np.dot(features, self.discriminator_weights)\n        # Apply sigmoid to get probability\n        return 1 / (1 + np.exp(-np.clip(logits, -500, 500)))\n\n    def extract_features(self, data: np.ndarray) -> np.ndarray:\n        """Extract domain-invariant features"""\n        # Simple linear feature extraction (in practice, this would be a neural network)\n        return np.dot(data, self.feature_extractor_weights)\n\n    def train_step(self, sim_features: np.ndarray, real_features: np.ndarray) -> Tuple[float, float]:\n        """Perform one training step for domain adaptation"""\n        # Extract features from both domains\n        sim_feat = self.extract_features(sim_features)\n        real_feat = self.extract_features(real_features)\n\n        # Train discriminator to distinguish domains\n        sim_pred = self.discriminator_forward(sim_feat)\n        real_pred = self.discriminator_forward(real_feat)\n\n        # Discriminator loss: should predict 0 for sim, 1 for real\n        disc_sim_loss = -np.log(1 - sim_pred + 1e-8)  # Want to predict 0\n        disc_real_loss = -np.log(real_pred + 1e-8)    # Want to predict 1\n        disc_loss = np.mean(disc_sim_loss + disc_real_loss)\n\n        # Update discriminator\n        disc_sim_grad = sim_pred  # Gradient for fake data (want to predict 0)\n        disc_real_grad = real_pred - 1  # Gradient for real data (want to predict 1)\n\n        avg_sim_grad = np.mean(sim_feat * disc_sim_grad[:, np.newaxis], axis=0)\n        avg_real_grad = np.mean(real_feat * disc_real_grad[:, np.newaxis], axis=0)\n\n        disc_grad = avg_sim_grad + avg_real_grad\n        self._update_discriminator(disc_grad)\n\n        # Train feature extractor to fool discriminator (minimize 1 - disc output)\n        # This means we want discriminator to predict 0.5 for both domains\n        feat_loss = np.mean(-np.log(sim_pred + 1e-8) - np.log(1 - real_pred + 1e-8))\n\n        # Update feature extractor to minimize domain discrepancy\n        feat_sim_grad = -(1 - sim_pred)  # Gradient to make discriminator output closer to 1\n        feat_real_grad = -real_pred      # Gradient to make discriminator output closer to 0\n\n        avg_sim_grad = np.mean(sim_feat * feat_sim_grad[:, np.newaxis], axis=0)\n        avg_real_grad = np.mean(real_feat * feat_real_grad[:, np.newaxis], axis=0)\n\n        feat_grad = avg_sim_grad + avg_real_grad\n        self._update_features(feat_grad)\n\n        return disc_loss, feat_loss\n\n    def _update_discriminator(self, grad: np.ndarray):\n        """Update discriminator weights using momentum"""\n        self.discriminator_optim[\'velocity\'] = (\n            self.discriminator_optim[\'momentum\'] * self.discriminator_optim[\'velocity\'] -\n            self.learning_rate * grad\n        )\n        self.discriminator_weights += self.discriminator_optim[\'velocity\']\n\n    def _update_features(self, grad: np.ndarray):\n        """Update feature extractor weights using momentum"""\n        self.feature_optim[\'velocity\'] = (\n            self.feature_optim[\'momentum\'] * self.feature_optim[\'velocity\'] -\n            self.learning_rate * grad\n        )\n        self.feature_extractor_weights += self.feature_optim[\'velocity\']\n'})}),"\n",(0,i.jsx)(e.h2,{id:"practical-implementation-guidelines",children:"Practical Implementation Guidelines"}),"\n",(0,i.jsx)(e.h3,{id:"sim-to-real-transfer-pipeline",children:"Sim-to-Real Transfer Pipeline"}),"\n",(0,i.jsx)(e.p,{children:"A comprehensive pipeline for sim-to-real transfer involves multiple stages:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class SimToRealPipeline:\n    """Complete pipeline for sim-to-real transfer"""\n\n    def __init__(self, robot_model: Dict[str, Any]):\n        self.robot_model = robot_model\n        self.visual_randomizer = VisualDomainRandomizer(DomainRandomizationParams())\n        self.physical_randomizer = PhysicalDomainRandomizer(PhysicalDomainParams())\n        self.system_identifier = GreyBoxSystemIdentifier(robot_model)\n        self.sensor_model = SensorNoiseModel()\n        self.adversarial_adapter = AdversarialDomainAdapter(feature_dim=128)\n        self.simulation_env = None\n        self.real_robot = None\n\n    def setup_simulation(self, env_config: Dict[str, Any]):\n        """Setup simulation environment with randomization"""\n        # Apply physical domain randomization\n        randomized_params = self.physical_randomizer.randomize_robot_parameters(\n            self.robot_model\n        )\n\n        # Update simulation with randomized parameters\n        self.simulation_env = self.create_simulation(randomized_params, env_config)\n\n    def collect_training_data(self, policy, num_episodes: int) -> Tuple[np.ndarray, ...]:\n        """Collect training data from simulation"""\n        sim_states = []\n        sim_actions = []\n        sim_rewards = []\n\n        for episode in range(num_episodes):\n            state = self.simulation_env.reset()\n            episode_states = []\n            episode_actions = []\n            episode_rewards = []\n\n            done = False\n            while not done:\n                action = policy.select_action(state)\n                next_state, reward, done, info = self.simulation_env.step(action)\n\n                episode_states.append(state)\n                episode_actions.append(action)\n                episode_rewards.append(reward)\n\n                state = next_state\n\n            sim_states.extend(episode_states)\n            sim_actions.extend(episode_actions)\n            sim_rewards.extend(episode_rewards)\n\n        return (\n            np.array(sim_states),\n            np.array(sim_actions),\n            np.array(sim_rewards)\n        )\n\n    def system_identification_phase(self, input_data: np.ndarray,\n                                  output_data: np.ndarray):\n        """Perform system identification to improve model accuracy"""\n        # Identify system parameters\n        identified_params = self.system_identifier.identify_parameters(\n            input_data, output_data\n        )\n\n        # Update robot model with identified parameters\n        self.update_robot_model(identified_params)\n\n    def adversarial_adaptation_phase(self, sim_features: np.ndarray,\n                                   real_features: np.ndarray,\n                                   num_steps: int = 1000):\n        """Perform adversarial domain adaptation"""\n        for step in range(num_steps):\n            disc_loss, feat_loss = self.adversarial_adapter.train_step(\n                sim_features, real_features\n            )\n\n            if step % 100 == 0:\n                print(f"Step {step}: Discriminator Loss: {disc_loss:.4f}, "\n                      f"Feature Loss: {feat_loss:.4f}")\n\n    def real_world_validation(self, policy, num_episodes: int = 10):\n        """Validate policy on real robot"""\n        if self.real_robot is None:\n            raise ValueError("Real robot not connected")\n\n        real_rewards = []\n\n        for episode in range(num_episodes):\n            state = self.real_robot.reset()\n            total_reward = 0\n            done = False\n\n            while not done:\n                # Apply sensor noise model to real observations\n                noisy_state = self.add_sensor_noise_to_state(state)\n\n                action = policy.select_action(noisy_state)\n                next_state, reward, done, info = self.real_robot.step(action)\n\n                total_reward += reward\n                state = next_state\n\n            real_rewards.append(total_reward)\n            print(f"Real episode {episode + 1}: Total reward = {total_reward}")\n\n        avg_reward = np.mean(real_rewards)\n        print(f"Average reward over {num_episodes} real episodes: {avg_reward}")\n        return avg_reward\n\n    def add_sensor_noise_to_state(self, state: np.ndarray) -> np.ndarray:\n        """Add realistic sensor noise to real robot state"""\n        # Apply appropriate noise models based on sensor types\n        # This is a simplified example - in practice, you\'d apply different\n        # noise models to different sensor modalities\n        noise_level = 0.01\n        noise = np.random.normal(0, noise_level, state.shape)\n        return state + noise\n\n    def create_simulation(self, params: Dict[str, Any],\n                         config: Dict[str, Any]) -> Any:\n        """Create simulation environment with specified parameters"""\n        # This would create a physics simulation environment\n        # (e.g., PyBullet, Gazebo, Mujoco) with the specified parameters\n        pass\n\n    def update_robot_model(self, params: Dict[str, Any]):\n        """Update robot model with new parameters"""\n        for param_name, param_value in params.items():\n            if param_name in self.robot_model:\n                self.robot_model[param_name] = param_value\n'})}),"\n",(0,i.jsx)(e.h2,{id:"evaluation-metrics-for-sim-to-real-transfer",children:"Evaluation Metrics for Sim-to-Real Transfer"}),"\n",(0,i.jsx)(e.p,{children:"Evaluating the effectiveness of sim-to-real transfer techniques requires appropriate metrics:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom typing import List, Dict, Any\n\nclass SimToRealEvaluator:\n    """Evaluates sim-to-real transfer effectiveness"""\n\n    def __init__(self):\n        self.metrics = {}\n\n    def policy_performance_gap(self, sim_rewards: List[float],\n                              real_rewards: List[float]) -> float:\n        """Calculate the performance gap between simulation and reality"""\n        sim_mean = np.mean(sim_rewards)\n        real_mean = np.mean(real_rewards)\n\n        if sim_mean != 0:\n            gap = abs(sim_mean - real_mean) / abs(sim_mean)\n        else:\n            gap = abs(real_mean) if real_mean != 0 else 0.0\n\n        return gap\n\n    def domain_similarity_score(self, sim_features: np.ndarray,\n                               real_features: np.ndarray) -> float:\n        """Calculate domain similarity using maximum mean discrepancy"""\n        from scipy.stats import wasserstein_distance\n\n        # Calculate Wasserstein distance between sim and real feature distributions\n        # This is a simplified version - in practice, you\'d use more sophisticated methods\n        distances = []\n        for i in range(sim_features.shape[1]):  # For each feature dimension\n            dist = wasserstein_distance(sim_features[:, i], real_features[:, i])\n            distances.append(dist)\n\n        # Return average distance (lower is better)\n        return np.mean(distances)\n\n    def transfer_success_rate(self, real_episodes: int,\n                            successful_episodes: int) -> float:\n        """Calculate the success rate of transfer to real world"""\n        return successful_episodes / real_episodes if real_episodes > 0 else 0.0\n\n    def evaluate_transfer_method(self, method_name: str,\n                                sim_rewards: List[float],\n                                real_rewards: List[float],\n                                sim_features: np.ndarray,\n                                real_features: np.ndarray) -> Dict[str, float]:\n        """Comprehensive evaluation of a transfer method"""\n        gap = self.policy_performance_gap(sim_rewards, real_rewards)\n        similarity = self.domain_similarity_score(sim_features, real_features)\n        success_rate = self.transfer_success_rate(len(real_rewards),\n                                                sum(1 for r in real_rewards if r > 0))\n\n        self.metrics[method_name] = {\n            \'performance_gap\': gap,\n            \'domain_similarity\': similarity,\n            \'success_rate\': success_rate,\n            \'sim_mean_reward\': np.mean(sim_rewards),\n            \'real_mean_reward\': np.mean(real_rewards)\n        }\n\n        return self.metrics[method_name]\n'})}),"\n",(0,i.jsx)(e.h2,{id:"best-practices-and-considerations",children:"Best Practices and Considerations"}),"\n",(0,i.jsx)(e.p,{children:"When implementing sim-to-real transfer techniques, consider the following best practices:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Start Simple"}),": Begin with basic domain randomization before implementing complex techniques"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Validate Gradually"}),": Test on simple tasks before moving to complex ones"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Monitor Reality Gap"}),": Continuously measure the performance gap between sim and real"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Use Multiple Sensors"}),": Leverage sensor fusion to reduce the impact of individual sensor inaccuracies"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Implement Safety Mechanisms"}),": Always have safety measures when deploying to real robots"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Iterative Improvement"}),": Continuously refine models based on real-world performance"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Robust Control"}),": Use robust control techniques that can handle model uncertainties"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"Sim-to-real transfer remains an active area of research with ongoing developments in techniques such as domain adaptation, system identification, and robust control. The key to success lies in understanding the specific challenges of your application domain and carefully selecting and tuning appropriate techniques."})]})}function p(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(m,{...n})}):m(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>t,x:()=>o});var i=a(6540);const s={},r=i.createContext(s);function t(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:t(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);