"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[6145],{1066:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var s=t(4848),o=t(8453);const r={title:"03 - Capstone Project Deployment",description:"Deploying the system on NVIDIA Jetson Orin hardware",sidebar_position:4,slug:"/physical-ai/capstone-project/03-deployment"},i="03 - Capstone Project Deployment",a={id:"capstone-project/deployment",title:"03 - Capstone Project Deployment",description:"Deploying the system on NVIDIA Jetson Orin hardware",source:"@site/docs/physical-ai/capstone-project/03-deployment.mdx",sourceDirName:"capstone-project",slug:"/physical-ai/capstone-project/03-deployment",permalink:"/physical-ai/capstone-project/03-deployment",draft:!1,unlisted:!1,editUrl:"https://github.com/MuhammadFuzail591/new-book-physical-ai/tree/main/docs/physical-ai/capstone-project/03-deployment.mdx",tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"03 - Capstone Project Deployment",description:"Deploying the system on NVIDIA Jetson Orin hardware",sidebar_position:4,slug:"/physical-ai/capstone-project/03-deployment"},sidebar:"tutorialSidebar",previous:{title:"02 - Capstone Project Implementation",permalink:"/physical-ai/capstone-project/02-implementation"},next:{title:"04 - Capstone Project Conclusion",permalink:"/physical-ai/capstone-project/04-conclusion"}},l={},c=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Deployment Overview",id:"deployment-overview",level:2},{value:"NVIDIA Jetson Orin Platform",id:"nvidia-jetson-orin-platform",level:2},{value:"Hardware Specifications",id:"hardware-specifications",level:3},{value:"Platform Advantages for Robotics",id:"platform-advantages-for-robotics",level:3},{value:"System Architecture for Deployment",id:"system-architecture-for-deployment",level:2},{value:"Hardware Abstraction Layer",id:"hardware-abstraction-layer",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Deployment Process",id:"deployment-process",level:2},{value:"Environment Setup",id:"environment-setup",level:3},{value:"Docker-based Deployment",id:"docker-based-deployment",level:3},{value:"Kubernetes for Multi-Node Deployment",id:"kubernetes-for-multi-node-deployment",level:3},{value:"Safety and Reliability",id:"safety-and-reliability",level:2},{value:"Safety Architecture",id:"safety-architecture",level:3},{value:"Monitoring and Logging",id:"monitoring-and-logging",level:3},{value:"Jetson Orin Deployment Instructions",id:"jetson-orin-deployment-instructions",level:2},{value:"Initial Setup",id:"initial-setup",level:3},{value:"Build and Deploy",id:"build-and-deploy",level:3},{value:"Launch Configuration",id:"launch-configuration",level:3},{value:"Testing and Validation",id:"testing-and-validation",level:2},{value:"Hardware Integration Testing",id:"hardware-integration-testing",level:3},{value:"Real-World Testing",id:"real-world-testing",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Summary",id:"summary",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"03---capstone-project-deployment",children:"03 - Capstone Project Deployment"}),"\n",(0,s.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,s.jsx)(n.p,{children:"By the end of this section, you will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Deploy the autonomous humanoid system on NVIDIA Jetson Orin hardware"}),"\n",(0,s.jsx)(n.li,{children:"Optimize system performance for embedded platform constraints"}),"\n",(0,s.jsx)(n.li,{children:"Configure system for real-world operation and safety requirements"}),"\n",(0,s.jsx)(n.li,{children:"Validate system functionality in real-world environments"}),"\n",(0,s.jsx)(n.li,{children:"Monitor and maintain deployed system performance"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"deployment-overview",children:"Deployment Overview"}),"\n",(0,s.jsx)(n.p,{children:"Deployment of the autonomous humanoid system on NVIDIA Jetson Orin represents the final step in bringing our design to life. This section covers the complete process of moving from simulation to real-world operation, including hardware setup, software optimization, and safety considerations."}),"\n",(0,s.jsx)(n.h2,{id:"nvidia-jetson-orin-platform",children:"NVIDIA Jetson Orin Platform"}),"\n",(0,s.jsx)(n.h3,{id:"hardware-specifications",children:"Hardware Specifications"}),"\n",(0,s.jsx)(n.p,{children:"The NVIDIA Jetson Orin platform provides the computational power needed for our autonomous humanoid system:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"GPU"}),": 2048-core NVIDIA Ampere architecture GPU"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"CPU"}),": 12-core ARM Hercules CPU"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Memory"}),": 32GB LPDDR5 memory (684GB/s)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Power"}),": Up to 60W operation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Connectivity"}),": Dual Gigabit Ethernet, PCIe Gen4 x4, 12x I2C, 6x SPI, 16x PWM, 24x GPIO"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"platform-advantages-for-robotics",children:"Platform Advantages for Robotics"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"AI Acceleration"}),": Dedicated Tensor Cores for AI inference"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Power Efficiency"}),": Optimized for mobile robotics applications"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Real-time Processing"}),": Low-latency processing for responsive behavior"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Connectivity"}),": Multiple interfaces for sensor and actuator integration"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ROS 2 Support"}),": Native support for ROS 2 framework"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"system-architecture-for-deployment",children:"System Architecture for Deployment"}),"\n",(0,s.jsx)(n.h3,{id:"hardware-abstraction-layer",children:"Hardware Abstraction Layer"}),"\n",(0,s.jsx)(n.p,{children:"The system uses a hardware abstraction layer to interface with the Jetson Orin platform:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Hardware Abstraction Layer for Jetson Orin\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, Imu, JointState\nfrom geometry_msgs.msg import Twist\nimport jetson.inference\nimport jetson.utils\nimport cv2\nimport numpy as np\n\nclass JetsonHardwareInterface(Node):\n    def __init__(self):\n        super().__init__('jetson_hardware_interface')\n\n        # Publishers for sensor data\n        self.camera_pub = self.create_publisher(Image, '/camera/rgb/image_raw', 10)\n        self.imu_pub = self.create_publisher(Imu, '/imu/data', 10)\n        self.joint_states_pub = self.create_publisher(JointState, '/joint_states', 10)\n\n        # Subscribers for commands\n        self.cmd_vel_sub = self.create_subscription(\n            Twist, '/cmd_vel', self.cmd_vel_callback, 10)\n\n        # Initialize Jetson hardware components\n        self.initialize_jetson_hardware()\n\n    def initialize_jetson_hardware(self):\n        # Initialize camera interface\n        self.camera = jetson.utils.gstCamera(640, 480, '/dev/video0')\n\n        # Initialize IMU interface\n        self.imu_interface = self.initialize_imu()\n\n        # Initialize joint control interface\n        self.joint_interface = self.initialize_joints()\n\n    def cmd_vel_callback(self, msg):\n        # Convert Twist command to actual motor control\n        linear_vel = msg.linear.x\n        angular_vel = msg.angular.z\n\n        # Send commands to actual motors\n        self.send_motor_commands(linear_vel, angular_vel)\n\n    def publish_sensor_data(self):\n        # Capture and publish camera data\n        img, width, height = self.camera.CaptureRGBA(zeroCopy=1)\n        img_msg = self.cv_bridge.cv2_to_imgmsg(img, encoding='rgba8')\n        self.camera_pub.publish(img_msg)\n\n        # Publish IMU data\n        imu_data = self.imu_interface.read_data()\n        self.imu_pub.publish(imu_data)\n\n        # Publish joint states\n        joint_states = self.joint_interface.get_states()\n        self.joint_states_pub.publish(joint_states)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsx)(n.p,{children:"The deployment requires optimization for the embedded platform constraints:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Performance Optimization Module\nimport psutil\nimport GPUtil\nimport threading\nimport time\nfrom collections import deque\n\nclass PerformanceOptimizer:\n    def __init__(self):\n        self.cpu_threshold = 80  # Percentage\n        self.gpu_threshold = 85  # Percentage\n        self.memory_threshold = 85  # Percentage\n        self.performance_history = deque(maxlen=100)\n\n    def monitor_resources(self):\n        """Monitor system resources and adjust performance accordingly"""\n        while True:\n            cpu_percent = psutil.cpu_percent(interval=1)\n            memory_percent = psutil.virtual_memory().percent\n            gpu_percent = self.get_gpu_utilization()\n\n            # Log performance data\n            perf_data = {\n                \'timestamp\': time.time(),\n                \'cpu_percent\': cpu_percent,\n                \'memory_percent\': memory_percent,\n                \'gpu_percent\': gpu_percent\n            }\n            self.performance_history.append(perf_data)\n\n            # Adjust system based on resource usage\n            if cpu_percent > self.cpu_threshold:\n                self.throttle_cpu_intensive_tasks()\n            if gpu_percent > self.gpu_threshold:\n                self.reduce_gpu_workload()\n            if memory_percent > self.memory_threshold:\n                self.cleanup_memory()\n\n            time.sleep(1)\n\n    def get_gpu_utilization(self):\n        """Get GPU utilization for Jetson platform"""\n        try:\n            gpus = GPUtil.getGPUs()\n            if gpus:\n                return gpus[0].load * 100\n            else:\n                # For Jetson, use nvidia-smi or jetson-stats\n                import subprocess\n                result = subprocess.run([\'nvidia-smi\', \'--query-gpu=utilization.gpu\', \'--format=csv,noheader,nounits\'],\n                                      capture_output=True, text=True)\n                if result.returncode == 0:\n                    return float(result.stdout.strip())\n        except:\n            return 0\n\n    def throttle_cpu_intensive_tasks(self):\n        """Reduce CPU-intensive tasks when under pressure"""\n        # Reduce perception processing frequency\n        # Reduce planning update rate\n        # Lower image processing resolution temporarily\n        pass\n\n    def reduce_gpu_workload(self):\n        """Reduce GPU-intensive tasks when under pressure"""\n        # Use lower resolution models\n        # Reduce batch size for inference\n        # Temporarily disable non-critical AI processing\n        pass\n\n    def cleanup_memory(self):\n        """Clean up memory when under pressure"""\n        # Clear perception result cache\n        # Reduce image buffer sizes\n        # Clear temporary data structures\n        pass\n'})}),"\n",(0,s.jsx)(n.h2,{id:"deployment-process",children:"Deployment Process"}),"\n",(0,s.jsx)(n.h3,{id:"environment-setup",children:"Environment Setup"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Flash Jetson Orin"}),": Install JetPack SDK with ROS 2 support"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Install Dependencies"}),": Install all required ROS 2 packages and AI frameworks"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Configure Network"}),": Set up networking for development and monitoring"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Test Hardware"}),": Verify all sensors and actuators are functioning"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"docker-based-deployment",children:"Docker-based Deployment"}),"\n",(0,s.jsx)(n.p,{children:"For consistent deployment across development and production environments:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-dockerfile",children:'# Dockerfile for Autonomous Humanoid System\nFROM nvcr.io/nvidia/ros:humble-ros-base-l4t-r35.4.1\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    python3-pip \\\n    python3-dev \\\n    build-essential \\\n    cmake \\\n    git \\\n    wget \\\n    curl \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nRUN pip3 install --upgrade pip && \\\n    pip3 install \\\n    torch torchvision torchaudio \\\n    whisper-openai \\\n    transformers \\\n    openai \\\n    opencv-python \\\n    jetson-inference \\\n    jetson-utils\n\n# Set up ROS 2 workspace\nWORKDIR /workspace\nCOPY . /workspace/src\nRUN source /opt/ros/humble/setup.bash && \\\n    colcon build --packages-select autonomous_humanoid_core perception_system voice_to_action cognitive_planning\n\n# Set up entrypoint\nCOPY entrypoint.sh /\nRUN chmod +x /entrypoint.sh\nENTRYPOINT ["/entrypoint.sh"]\nCMD ["bash"]\n'})}),"\n",(0,s.jsx)(n.h3,{id:"kubernetes-for-multi-node-deployment",children:"Kubernetes for Multi-Node Deployment"}),"\n",(0,s.jsx)(n.p,{children:"For complex humanoid robots with multiple processing nodes:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# deployment.yaml - Autonomous Humanoid System on Kubernetes\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: autonomous-humanoid-core\n  namespace: robotics\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: autonomous-humanoid-core\n  template:\n    metadata:\n      labels:\n        app: autonomous-humanoid-core\n    spec:\n      nodeSelector:\n        hardware: jetson-orin\n      containers:\n      - name: core-system\n        image: autonomous-humanoid:latest\n        resources:\n          limits:\n            cpu: "10"\n            memory: "20Gi"\n            nvidia.com/gpu: 1\n          requests:\n            cpu: "4"\n            memory: "8Gi"\n            nvidia.com/gpu: 1\n        env:\n        - name: ROS_DOMAIN_ID\n          value: "1"\n        - name: NVIDIA_VISIBLE_DEVICES\n          value: "all"\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: usb-devices\n          mountPath: /dev/bus/usb\n        - name: sensors\n          mountPath: /dev/sensors\n      volumes:\n      - name: usb-devices\n        hostPath:\n          path: /dev/bus/usb\n      - name: sensors\n        hostPath:\n          path: /dev/sensors\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: autonomous-humanoid-service\n  namespace: robotics\nspec:\n  selector:\n    app: autonomous-humanoid-core\n  ports:\n  - protocol: TCP\n    port: 9090\n    targetPort: 9090\n  type: LoadBalancer\n'})}),"\n",(0,s.jsx)(n.h2,{id:"safety-and-reliability",children:"Safety and Reliability"}),"\n",(0,s.jsx)(n.h3,{id:"safety-architecture",children:"Safety Architecture"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Safety System for Autonomous Humanoid\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Bool, String\nfrom sensor_msgs.msg import LaserScan, Imu\nfrom geometry_msgs.msg import Twist\n\nclass SafetySystem(Node):\n    def __init__(self):\n        super().__init__('safety_system')\n\n        # Publishers for safety commands\n        self.emergency_stop_pub = self.create_publisher(Bool, '/emergency_stop', 10)\n        self.safety_status_pub = self.create_publisher(String, '/safety_status', 10)\n\n        # Subscribers for safety-critical data\n        self.laser_scan_sub = self.create_subscription(\n            LaserScan, '/scan', self.laser_scan_callback, 10)\n        self.imu_sub = self.create_subscription(\n            Imu, '/imu/data', self.imu_callback, 10)\n        self.cmd_vel_sub = self.create_subscription(\n            Twist, '/cmd_vel', self.cmd_vel_callback, 10)\n\n        # Safety parameters\n        self.safety_distance = 0.5  # meters\n        self.tilt_threshold = 30.0  # degrees\n        self.emergency_stop_active = False\n\n        # Timer for safety checks\n        self.safety_timer = self.create_timer(0.1, self.safety_check_callback)\n\n    def laser_scan_callback(self, msg):\n        # Check for obstacles in path\n        if min(msg.ranges) < self.safety_distance:\n            self.trigger_safety_stop(\"Obstacle detected too close\")\n\n    def imu_callback(self, msg):\n        # Check for dangerous tilts\n        roll, pitch, yaw = self.quaternion_to_euler(\n            msg.orientation.x,\n            msg.orientation.y,\n            msg.orientation.z,\n            msg.orientation.w\n        )\n\n        if abs(roll) > self.tilt_threshold or abs(pitch) > self.tilt_threshold:\n            self.trigger_safety_stop(\"Dangerous tilt detected\")\n\n    def cmd_vel_callback(self, msg):\n        # Validate velocity commands\n        if abs(msg.linear.x) > 1.0 or abs(msg.angular.z) > 1.0:\n            self.get_logger().warn(\"High velocity command detected\")\n\n    def safety_check_callback(self):\n        # Perform periodic safety checks\n        if self.emergency_stop_active:\n            # Publish emergency stop command\n            stop_msg = Bool()\n            stop_msg.data = True\n            self.emergency_stop_pub.publish(stop_msg)\n\n    def trigger_safety_stop(self, reason):\n        self.get_logger().error(f\"Safety stop triggered: {reason}\")\n        self.emergency_stop_active = True\n\n        # Publish safety status\n        status_msg = String()\n        status_msg.data = f\"EMERGENCY_STOP: {reason}\"\n        self.safety_status_pub.publish(status_msg)\n\n    def quaternion_to_euler(self, x, y, z, w):\n        # Convert quaternion to Euler angles\n        import math\n        t0 = +2.0 * (w * x + y * z)\n        t1 = +1.0 - 2.0 * (x * x + y * y)\n        roll = math.atan2(t0, t1)\n\n        t2 = +2.0 * (w * y - z * x)\n        t2 = +1.0 if t2 > +1.0 else t2\n        t2 = -1.0 if t2 < -1.0 else t2\n        pitch = math.asin(t2)\n\n        t3 = +2.0 * (w * z + x * y)\n        t4 = +1.0 - 2.0 * (y * y + z * z)\n        yaw = math.atan2(t3, t4)\n\n        return roll * 180.0 / math.pi, pitch * 180.0 / math.pi, yaw * 180.0 / math.pi\n"})}),"\n",(0,s.jsx)(n.h3,{id:"monitoring-and-logging",children:"Monitoring and Logging"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# System Monitoring for Autonomous Humanoid\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nimport psutil\nimport time\nimport json\n\nclass SystemMonitor(Node):\n    def __init__(self):\n        super().__init__('system_monitor')\n\n        self.monitor_pub = self.create_publisher(String, '/system_monitor', 10)\n\n        # Timer for monitoring\n        self.monitor_timer = self.create_timer(5.0, self.monitor_system)\n\n    def monitor_system(self):\n        # Collect system metrics\n        metrics = {\n            'timestamp': time.time(),\n            'cpu_percent': psutil.cpu_percent(interval=1),\n            'memory_percent': psutil.virtual_memory().percent,\n            'disk_usage': psutil.disk_usage('/').percent,\n            'temperature': self.get_jetson_temperature(),\n            'power_consumption': self.get_power_consumption()\n        }\n\n        # Publish metrics\n        metrics_msg = String()\n        metrics_msg.data = json.dumps(metrics)\n        self.monitor_pub.publish(metrics_msg)\n\n        # Log metrics\n        self.get_logger().info(f\"System Metrics: {metrics}\")\n\n    def get_jetson_temperature(self):\n        \"\"\"Get temperature from Jetson thermal sensors\"\"\"\n        try:\n            with open('/sys/class/thermal/thermal_zone0/temp', 'r') as f:\n                temp = int(f.read().strip()) / 1000.0\n                return temp\n        except:\n            return 0.0\n\n    def get_power_consumption(self):\n        \"\"\"Get power consumption (if available)\"\"\"\n        try:\n            # This would interface with Jetson power management\n            # For now, return a simulated value\n            return 45.0  # watts\n        except:\n            return 0.0\n"})}),"\n",(0,s.jsx)(n.h2,{id:"jetson-orin-deployment-instructions",children:"Jetson Orin Deployment Instructions"}),"\n",(0,s.jsx)(n.h3,{id:"initial-setup",children:"Initial Setup"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Flash Jetson Orin"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Download and install JetPack\nwget https://developer.nvidia.com/jetpack-sdk-50\nsudo ./JetPack-5.0-linux-x64_b42.run\n\n# Flash the device using SDK Manager\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Install ROS 2 Humble"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Add ROS 2 repository\nsudo apt update && sudo apt install software-properties-common\nsudo add-apt-repository universe\n\n# Install ROS 2 Humble\nsudo apt update && sudo apt install -y \\\n    ros-humble-desktop \\\n    ros-humble-ros-base \\\n    python3-rosdep \\\n    python3-argcomplete \\\n    python3-colcon-common-extensions\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Install Isaac ROS"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Add Isaac ROS repository\nsudo apt update\nsudo apt install -y nvidia-isaacl-ros-core\nsudo apt install -y nvidia-isaacl-ros-perception\nsudo apt install -y nvidia-isaacl-ros-navigation\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"build-and-deploy",children:"Build and Deploy"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Source ROS 2\nsource /opt/ros/humble/setup.bash\n\n# Create workspace\nmkdir -p ~/autonomous_humanoid_ws/src\ncd ~/autonomous_humanoid_ws\n\n# Copy source code\ncp -r /path/to/your/robotic/project/src/* ~/autonomous_humanoid_ws/src/\n\n# Install dependencies\nrosdep install --from-paths src --ignore-src -r -y\n\n# Build the project\ncolcon build --packages-select autonomous_humanoid_core perception_system voice_to_action cognitive_planning\n\n# Source the workspace\nsource install/setup.bash\n\n# Run the system\nros2 launch autonomous_humanoid_core deploy.launch.py\n"})}),"\n",(0,s.jsx)(n.h3,{id:"launch-configuration",children:"Launch Configuration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:"\x3c!-- deploy.launch.py --\x3e\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import LaunchConfiguration\n\ndef generate_launch_description():\n    use_sim_time = LaunchConfiguration('use_sim_time', default='false')\n\n    return LaunchDescription([\n        DeclareLaunchArgument(\n            'use_sim_time',\n            default_value='false',\n            description='Use simulation (Gazebo) clock if true'),\n\n        Node(\n            package='autonomous_humanoid_core',\n            executable='autonomous_humanoid_core',\n            name='autonomous_humanoid_core',\n            parameters=[{'use_sim_time': use_sim_time}],\n            output='screen'),\n\n        Node(\n            package='perception_system',\n            executable='perception_system',\n            name='perception_system',\n            parameters=[{'use_sim_time': use_sim_time}],\n            output='screen'),\n\n        Node(\n            package='voice_to_action',\n            executable='voice_to_action',\n            name='voice_to_action',\n            parameters=[{'use_sim_time': use_sim_time}],\n            output='screen'),\n\n        Node(\n            package='cognitive_planning',\n            executable='cognitive_planning',\n            name='cognitive_planning',\n            parameters=[{'use_sim_time': use_sim_time}],\n            output='screen'),\n\n        Node(\n            package='safety_system',\n            executable='safety_system',\n            name='safety_system',\n            parameters=[{'use_sim_time': use_sim_time}],\n            output='screen'),\n    ])\n"})}),"\n",(0,s.jsx)(n.h2,{id:"testing-and-validation",children:"Testing and Validation"}),"\n",(0,s.jsx)(n.h3,{id:"hardware-integration-testing",children:"Hardware Integration Testing"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Sensor Validation"}),": Verify all sensors are publishing correct data"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Actuator Testing"}),": Test all actuators respond to commands"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Communication Testing"}),": Validate ROS 2 communication between nodes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance Testing"}),": Measure system performance under load"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"real-world-testing",children:"Real-World Testing"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Safe Environment"}),": Test in controlled, safe environment first"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Gradual Complexity"}),": Increase task complexity gradually"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Edge Cases"}),": Test boundary conditions and error scenarios"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Long-term Operation"}),": Validate system stability over extended periods"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Deployment Challenge"}),": Create a deployment script that automates the entire setup process for the Jetson Orin platform."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Performance Analysis"}),": Analyze the performance of different components on the Jetson platform and propose optimization strategies."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Safety Enhancement"}),": Implement additional safety mechanisms for outdoor operation and human interaction scenarios."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"Deployment on the NVIDIA Jetson Orin platform brings our autonomous humanoid system to life in the real world. Through careful optimization for embedded constraints, comprehensive safety systems, and thorough validation, we ensure reliable operation in real-world environments. The deployment process demonstrates the practical application of all technologies learned throughout this textbook in a complete, functional robotic system."})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(m,{...e})}):m(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>a});var s=t(6540);const o={},r=s.createContext(o);function i(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);