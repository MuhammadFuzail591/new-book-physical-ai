"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[7817],{1199:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>a,metadata:()=>r,toc:()=>l});var i=t(4848),o=t(8453);const a={title:"Voice-to-Action Command Processing in Robotics"},s="Voice-to-Action Command Processing in Robotics",r={id:"physical-ai/voice-robotics/voice-to-action",title:"Voice-to-Action Command Processing in Robotics",description:"Introduction to Voice Command Processing",source:"@site/docs/physical-ai/voice-robotics/voice-to-action.mdx",sourceDirName:"physical-ai/voice-robotics",slug:"/physical-ai/voice-robotics/voice-to-action",permalink:"/physical-ai-textbook/physical-ai/physical-ai/voice-robotics/voice-to-action",draft:!1,unlisted:!1,editUrl:"https://github.com/your-username/physical-ai-textbook/tree/main/docs/physical-ai/voice-robotics/voice-to-action.mdx",tags:[],version:"current",frontMatter:{title:"Voice-to-Action Command Processing in Robotics"},sidebar:"tutorialSidebar",previous:{title:"whisper-integration",permalink:"/physical-ai-textbook/physical-ai/physical-ai/voice-robotics/whisper-integration"},next:{title:"chapter-summary",permalink:"/physical-ai-textbook/physical-ai/physical-ai/voice-robotics/chapter-summary"}},c={},l=[{value:"Introduction to Voice Command Processing",id:"introduction-to-voice-command-processing",level:2},{value:"Command Structure and Classification",id:"command-structure-and-classification",level:2},{value:"Command Categories",id:"command-categories",level:3},{value:"Command Parsing Architecture",id:"command-parsing-architecture",level:3},{value:"Context-Aware Command Processing",id:"context-aware-command-processing",level:2},{value:"Maintaining Conversation Context",id:"maintaining-conversation-context",level:3},{value:"Command Validation and Safety Checking",id:"command-validation-and-safety-checking",level:2},{value:"Safety Validation Pipeline",id:"safety-validation-pipeline",level:3},{value:"Error Recovery and Fallback Mechanisms",id:"error-recovery-and-fallback-mechanisms",level:2},{value:"Command Recovery Strategies",id:"command-recovery-strategies",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Optimizing Voice Command Processing",id:"optimizing-voice-command-processing",level:3}];function m(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h1,{id:"voice-to-action-command-processing-in-robotics",children:"Voice-to-Action Command Processing in Robotics"}),"\n",(0,i.jsx)(e.h2,{id:"introduction-to-voice-command-processing",children:"Introduction to Voice Command Processing"}),"\n",(0,i.jsx)(e.p,{children:"Voice-to-action processing in robotics involves converting spoken natural language commands into executable robot actions. This process requires multiple sophisticated components working in harmony: speech recognition, natural language understanding, command mapping, and action execution. The goal is to create an intuitive interface that allows humans to communicate with robots using natural language, similar to how we communicate with other humans."}),"\n",(0,i.jsx)(e.p,{children:"The voice-to-action pipeline can be broken down into several stages:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Speech Recognition"}),": Converting audio to text"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Natural Language Understanding"}),": Interpreting the meaning of commands"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Command Mapping"}),": Translating understood commands to robot actions"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Action Execution"}),": Executing mapped actions on the robot"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Feedback Generation"}),": Providing confirmation or error feedback"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"command-structure-and-classification",children:"Command Structure and Classification"}),"\n",(0,i.jsx)(e.h3,{id:"command-categories",children:"Command Categories"}),"\n",(0,i.jsx)(e.p,{children:"Robotic voice commands can typically be categorized into several types:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Navigation Commands"}),": Directing the robot to move to specific locations"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:'"Go to the kitchen"'}),"\n",(0,i.jsx)(e.li,{children:'"Come here"'}),"\n",(0,i.jsx)(e.li,{children:'"Move forward 2 meters"'}),"\n",(0,i.jsx)(e.li,{children:'"Turn left"'}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Manipulation Commands"}),": Instructing the robot to interact with objects"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:'"Pick up the red cup"'}),"\n",(0,i.jsx)(e.li,{children:'"Place the book on the table"'}),"\n",(0,i.jsx)(e.li,{children:'"Open the door"'}),"\n",(0,i.jsx)(e.li,{children:'"Grab the pen"'}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Information Commands"}),": Requesting information from the robot"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:'"What time is it?"'}),"\n",(0,i.jsx)(e.li,{children:'"Tell me about yourself"'}),"\n",(0,i.jsx)(e.li,{children:'"What can you do?"'}),"\n",(0,i.jsx)(e.li,{children:'"Where are you?"'}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Interaction Commands"}),": Initiating social interactions"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:'"Say hello to John"'}),"\n",(0,i.jsx)(e.li,{children:'"Introduce yourself"'}),"\n",(0,i.jsx)(e.li,{children:'"Follow me"'}),"\n",(0,i.jsx)(e.li,{children:'"Wait here"'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"command-parsing-architecture",children:"Command Parsing Architecture"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import re\nimport spacy\nfrom typing import Dict, List, Tuple, Optional\n\nclass VoiceCommandParser:\n    def __init__(self):\n        # Load spaCy model for linguistic analysis\n        try:\n            self.nlp = spacy.load(\"en_core_web_sm\")\n        except OSError:\n            print(\"spaCy English model not found. Install with: python -m spacy download en_core_web_sm\")\n            self.nlp = None\n\n        # Define command patterns and templates\n        self.command_patterns = {\n            'navigation': [\n                r'go to (?:the )?(?P<location>\\w+(?: \\w+)*)',\n                r'move to (?:the )?(?P<location>\\w+(?: \\w+)*)',\n                r'navigate to (?:the )?(?P<location>\\w+(?: \\w+)*)',\n                r'come (?:here|to me)',\n                r'move (?:forward|backward|left|right)',\n                r'go (?:forward|backward|left|right)'\n            ],\n            'manipulation': [\n                r'(?:pick up|grab|take) (?:the )?(?P<object>\\w+(?: \\w+)*)',\n                r'place (?:the )?(?P<object>\\w+(?: \\w+)*) (?:on|at) (?:the )?(?P<destination>\\w+(?: \\w+)*)',\n                r'put (?:the )?(?P<object>\\w+(?: \\w+)*) (?:on|at) (?:the )?(?P<destination>\\w+(?: \\w+)*)',\n                r'open (?:the )?(?P<object>\\w+(?: \\w+)*)',\n                r'close (?:the )?(?P<object>\\w+(?: \\w+)*)'\n            ],\n            'information': [\n                r'what time is it',\n                r'tell me about yourself',\n                r'introduce yourself',\n                r'what can you do',\n                r'where are you'\n            ],\n            'interaction': [\n                r'say hello to (?P<name>\\w+)',\n                r'introduce yourself(?: to (?P<name>\\w+))?',\n                r'follow me',\n                r'wait here',\n                r'stop'\n            ]\n        }\n\n        # Define entity extraction patterns\n        self.entity_patterns = {\n            'location': [r'kitchen', r'bedroom', r'living room', r'bathroom', r'office', r'dining room'],\n            'object': [r'cup', r'book', r'pen', r'ball', r'box', r'table', r'chair', r'door'],\n            'action': [r'pick', r'place', r'grab', r'open', r'close', r'move', r'go'],\n            'direction': [r'forward', r'backward', r'left', r'right', r'up', r'down']\n        }\n\n    def parse_command(self, text: str) -> Dict:\n        \"\"\"\n        Parse a voice command and extract its components\n        \"\"\"\n        text_lower = text.lower().strip()\n\n        # Use regex patterns to identify command type\n        command_type = self.identify_command_type(text_lower)\n\n        # Extract entities using NLP if available\n        entities = self.extract_entities(text_lower)\n\n        # Perform syntactic analysis\n        syntax_analysis = self.analyze_syntax(text_lower)\n\n        # Generate action plan\n        action_plan = self.generate_action_plan(command_type, entities)\n\n        return {\n            'raw_text': text,\n            'command_type': command_type,\n            'entities': entities,\n            'syntax_analysis': syntax_analysis,\n            'action_plan': action_plan,\n            'confidence': self.calculate_confidence(text_lower, command_type, entities)\n        }\n\n    def identify_command_type(self, text: str) -> str:\n        \"\"\"\n        Identify the type of command using regex patterns\n        \"\"\"\n        for cmd_type, patterns in self.command_patterns.items():\n            for pattern in patterns:\n                match = re.search(pattern, text)\n                if match:\n                    return cmd_type\n\n        # If no pattern matches, return 'unknown'\n        return 'unknown'\n\n    def extract_entities(self, text: str) -> Dict[str, List[str]]:\n        \"\"\"\n        Extract named entities from the command text\n        \"\"\"\n        entities = {\n            'location': [],\n            'object': [],\n            'person': [],\n            'action': [],\n            'direction': [],\n            'other': []\n        }\n\n        # If spaCy is available, use it for entity extraction\n        if self.nlp:\n            doc = self.nlp(text)\n\n            # Extract named entities\n            for ent in doc.ents:\n                if ent.label_ in ['GPE', 'LOC', 'FAC']:  # Geopolitical, location, facility\n                    entities['location'].append(ent.text)\n                elif ent.label_ == 'PERSON':\n                    entities['person'].append(ent.text)\n                elif ent.label_ in ['OBJECT', 'PRODUCT']:  # These might not be standard labels\n                    entities['object'].append(ent.text)\n\n            # Extract noun chunks as potential objects\n            for chunk in doc.noun_chunks:\n                if chunk.text != chunk.root.text:  # Skip single-word chunks for now\n                    entities['object'].append(chunk.text)\n\n        # Use pattern-based extraction as fallback\n        for entity_type, patterns in self.entity_patterns.items():\n            for pattern in patterns:\n                matches = re.findall(pattern, text, re.IGNORECASE)\n                entities[entity_type].extend(matches)\n\n        # Remove duplicates while preserving order\n        for key in entities:\n            entities[key] = list(dict.fromkeys(entities[key]))\n\n        return entities\n\n    def analyze_syntax(self, text: str) -> Dict:\n        \"\"\"\n        Perform basic syntactic analysis\n        \"\"\"\n        if not self.nlp:\n            # Simple fallback without NLP\n            words = text.split()\n            return {\n                'verb': words[0] if words else None,  # Very basic assumption\n                'noun_phrase': ' '.join(words[1:]) if len(words) > 1 else None,\n                'pos_tags': [(word, 'UNKNOWN') for word in words]\n            }\n\n        doc = self.nlp(text)\n\n        # Extract verbs (actions)\n        verbs = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n\n        # Extract subjects and objects\n        subjects = [chunk.text for chunk in doc.noun_chunks if any(token.dep_ == 'nsubj' for token in chunk)]\n        objects = [chunk.text for chunk in doc.noun_chunks if any(token.dep_ == 'dobj' for token in chunk)]\n\n        # Extract dependencies\n        dependencies = [(token.text, token.dep_, token.head.text) for token in doc]\n\n        return {\n            'verbs': verbs,\n            'subjects': subjects,\n            'objects': objects,\n            'dependencies': dependencies,\n            'pos_tags': [(token.text, token.pos_) for token in doc]\n        }\n\n    def generate_action_plan(self, command_type: str, entities: Dict) -> List[Dict]:\n        \"\"\"\n        Generate an action plan based on command type and entities\n        \"\"\"\n        action_plan = []\n\n        if command_type == 'navigation':\n            if entities['location']:\n                for location in entities['location']:\n                    action_plan.append({\n                        'action_type': 'navigation',\n                        'target': location,\n                        'parameters': {}\n                    })\n            elif 'here' in entities.get('direction', []) or 'me' in str(entities):\n                action_plan.append({\n                    'action_type': 'navigation',\n                    'target': 'user_location',\n                    'parameters': {}\n                })\n            elif entities['direction']:\n                for direction in entities['direction']:\n                    action_plan.append({\n                        'action_type': 'move',\n                        'direction': direction,\n                        'distance': 1.0,  # Default distance\n                        'parameters': {}\n                    })\n\n        elif command_type == 'manipulation':\n            if entities['object']:\n                for obj in entities['object']:\n                    action = 'pick'  # Default action\n                    if any(word in ['place', 'put', 'on', 'at'] for word in entities.get('other', [])):\n                        action = 'place'\n                    elif any(word in ['open', 'close'] for word in entities.get('action', [])):\n                        action = entities['action'][0] if entities['action'] else 'manipulate'\n\n                    action_plan.append({\n                        'action_type': 'manipulation',\n                        'object': obj,\n                        'action': action,\n                        'destination': entities['location'][0] if entities['location'] else None,\n                        'parameters': {}\n                    })\n\n        elif command_type == 'information':\n            for entity in entities.get('other', []):\n                if 'time' in entity:\n                    action_plan.append({\n                        'action_type': 'information',\n                        'request': 'time',\n                        'parameters': {}\n                    })\n                elif 'yourself' in entity or 'introduce' in entity:\n                    action_plan.append({\n                        'action_type': 'information',\n                        'request': 'self_introduction',\n                        'parameters': {}\n                    })\n\n        elif command_type == 'interaction':\n            if 'follow' in str(entities) or 'me' in str(entities):\n                action_plan.append({\n                    'action_type': 'interaction',\n                    'interaction_type': 'follow',\n                    'target': 'user',\n                    'parameters': {}\n                })\n            elif 'hello' in str(entities) or 'hi' in str(entities):\n                action_plan.append({\n                    'action_type': 'interaction',\n                    'interaction_type': 'greet',\n                    'target': entities['person'][0] if entities['person'] else 'user',\n                    'parameters': {}\n                })\n\n        return action_plan\n\n    def calculate_confidence(self, text: str, command_type: str, entities: Dict) -> float:\n        \"\"\"\n        Calculate confidence score for the parsed command\n        \"\"\"\n        confidence = 0.0\n\n        # Base confidence on command type identification\n        if command_type != 'unknown':\n            confidence += 0.5\n        else:\n            return 0.0  # If unknown, confidence is 0\n\n        # Boost confidence if entities are found\n        entity_count = sum(len(v) for v in entities.values())\n        if entity_count > 0:\n            confidence += 0.3 * min(entity_count / 5.0, 1.0)  # Up to 0.3 bonus\n\n        # Additional confidence boost based on text length and structure\n        if len(text.split()) >= 3:  # Reasonable command length\n            confidence += 0.2\n\n        return min(confidence, 1.0)  # Cap at 1.0\n"})}),"\n",(0,i.jsx)(e.h2,{id:"context-aware-command-processing",children:"Context-Aware Command Processing"}),"\n",(0,i.jsx)(e.h3,{id:"maintaining-conversation-context",children:"Maintaining Conversation Context"}),"\n",(0,i.jsx)(e.p,{children:"For more sophisticated voice-to-action systems, maintaining context is crucial for understanding ambiguous commands:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"from datetime import datetime, timedelta\nfrom typing import Any, Dict, List\n\nclass ContextAwareCommandProcessor:\n    def __init__(self, context_window_minutes=5):\n        self.context_window = timedelta(minutes=context_window_minutes)\n        self.conversation_history = []\n        self.current_context = {}\n        self.last_command_time = None\n\n    def process_command_with_context(self, command_text: str, user_id: str = \"default_user\") -> Dict:\n        \"\"\"\n        Process a command while considering the conversation context\n        \"\"\"\n        current_time = datetime.now()\n\n        # Update context based on time elapsed\n        self.update_context_for_time(current_time)\n\n        # Add current command to history\n        command_entry = {\n            'text': command_text,\n            'user_id': user_id,\n            'timestamp': current_time,\n            'processed': False\n        }\n        self.conversation_history.append(command_entry)\n\n        # Parse the command\n        parsed_command = self.parse_command(command_text)\n\n        # Apply context-aware disambiguation\n        disambiguated_command = self.apply_context_disambiguation(parsed_command)\n\n        # Update internal context\n        self.update_internal_context(disambiguated_command, current_time)\n\n        # Generate response\n        response = {\n            'original_command': command_text,\n            'parsed_command': disambiguated_command,\n            'context_used': self.current_context.copy(),\n            'timestamp': current_time\n        }\n\n        # Mark command as processed\n        command_entry['processed'] = True\n        command_entry['result'] = response\n\n        return response\n\n    def update_context_for_time(self, current_time: datetime):\n        \"\"\"\n        Clean up old context entries based on time window\n        \"\"\"\n        cutoff_time = current_time - self.context_window\n\n        # Remove old entries from history\n        self.conversation_history = [\n            entry for entry in self.conversation_history\n            if entry['timestamp'] > cutoff_time\n        ]\n\n        # Update last command time\n        if self.conversation_history:\n            self.last_command_time = self.conversation_history[-1]['timestamp']\n        else:\n            self.last_command_time = None\n\n    def apply_context_disambiguation(self, parsed_command: Dict) -> Dict:\n        \"\"\"\n        Apply context to disambiguate the parsed command\n        \"\"\"\n        command_type = parsed_command['command_type']\n        entities = parsed_command['entities']\n\n        # If command is navigation-related and no specific location is mentioned\n        if command_type == 'navigation' and not entities['location']:\n            # Check if user previously mentioned a location\n            recent_locations = self.get_recent_entities('location', minutes=10)\n            if recent_locations:\n                # Use the most recent location\n                entities['location'] = [recent_locations[-1]]\n                parsed_command['entities'] = entities\n                parsed_command['disambiguated'] = True\n                parsed_command['reason'] = f\"Using context: location '{recent_locations[-1]}' from previous command\"\n\n        # If command is manipulation-related and no specific object is mentioned\n        elif command_type == 'manipulation' and not entities['object']:\n            # Check if user previously mentioned an object\n            recent_objects = self.get_recent_entities('object', minutes=5)\n            if recent_objects:\n                # Use the most recent object\n                entities['object'] = [recent_objects[-1]]\n                parsed_command['entities'] = entities\n                parsed_command['disambiguated'] = True\n                parsed_command['reason'] = f\"Using context: object '{recent_objects[-1]}' from previous command\"\n\n        # If command refers to \"it\" or \"that\"\n        elif any(pronoun in parsed_command['raw_text'].lower() for pronoun in ['it', 'that', 'there']):\n            # Look for recently mentioned objects or locations\n            recent_objects = self.get_recent_entities('object', minutes=5)\n            recent_locations = self.get_recent_entities('location', minutes=5)\n\n            # Prioritize objects over locations for \"it\" and \"that\"\n            if recent_objects:\n                entities['object'] = [recent_objects[-1]]\n                parsed_command['entities'] = entities\n                parsed_command['disambiguated'] = True\n                parsed_command['reason'] = f\"Using context: '{recent_objects[-1]}' referred to as 'it/that'\"\n            elif recent_locations:\n                entities['location'] = [recent_locations[-1]]\n                parsed_command['entities'] = entities\n                parsed_command['disambiguated'] = True\n                parsed_command['reason'] = f\"Using context: '{recent_locations[-1]}' referred to as 'it/there'\"\n\n        return parsed_command\n\n    def get_recent_entities(self, entity_type: str, minutes: int = 5) -> List[str]:\n        \"\"\"\n        Get entities of a specific type from recent commands\n        \"\"\"\n        cutoff_time = datetime.now() - timedelta(minutes=minutes)\n        recent_entities = []\n\n        for entry in reversed(self.conversation_history):\n            if entry['timestamp'] > cutoff_time and 'result' in entry:\n                entities = entry['result']['parsed_command']['entities']\n                if entity_type in entities:\n                    recent_entities.extend(entities[entity_type])\n\n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(recent_entities))\n\n    def update_internal_context(self, parsed_command: Dict, timestamp: datetime):\n        \"\"\"\n        Update internal context based on the processed command\n        \"\"\"\n        # Update current location if navigation command was successful\n        if parsed_command['command_type'] == 'navigation' and parsed_command['entities']['location']:\n            self.current_context['current_location'] = parsed_command['entities']['location'][0]\n            self.current_context['last_navigation_time'] = timestamp\n\n        # Update held object if manipulation command was successful\n        if parsed_command['command_type'] == 'manipulation':\n            action = parsed_command.get('action_plan', [{}])[0].get('action', '') if parsed_command.get('action_plan') else ''\n            if action == 'pick' and parsed_command['entities']['object']:\n                self.current_context['held_object'] = parsed_command['entities']['object'][0]\n            elif action == 'place':\n                self.current_context.pop('held_object', None)  # Remove held object when placed\n\n    def get_conversation_summary(self) -> Dict:\n        \"\"\"\n        Get a summary of the current conversation state\n        \"\"\"\n        return {\n            'total_commands': len(self.conversation_history),\n            'active_context': self.current_context,\n            'recent_commands': [\n                {\n                    'text': entry['text'],\n                    'timestamp': entry['timestamp'].isoformat(),\n                    'processed': entry.get('processed', False)\n                }\n                for entry in self.conversation_history[-5:]  # Last 5 commands\n            ]\n        }\n"})}),"\n",(0,i.jsx)(e.h2,{id:"command-validation-and-safety-checking",children:"Command Validation and Safety Checking"}),"\n",(0,i.jsx)(e.h3,{id:"safety-validation-pipeline",children:"Safety Validation Pipeline"}),"\n",(0,i.jsx)(e.p,{children:"Before executing voice commands, it's crucial to validate them for safety and feasibility:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import rospy\nfrom geometry_msgs.msg import Point\nfrom sensor_msgs.msg import LaserScan\nfrom typing import Dict, List, Tuple\n\nclass CommandSafetyValidator:\n    def __init__(self):\n        # Subscribe to relevant sensor topics\n        self.laser_sub = rospy.Subscriber('/scan', LaserScan, self.laser_callback)\n        self.odom_sub = rospy.Subscriber('/odom', Odometry, self.odom_callback)\n\n        # Store current sensor data\n        self.current_scan = None\n        self.current_odom = None\n        self.robot_radius = 0.3  # Robot radius in meters\n\n        # Define safety zones and constraints\n        self.safety_zones = {\n            'forbidden_areas': [],  # List of Polygon points\n            'restricted_heights': (0.1, 1.5),  # (min, max) in meters\n            'speed_limits': {'navigation': 0.5, 'manipulation': 0.1}\n        }\n\n    def laser_callback(self, scan_msg):\n        \"\"\"Update current laser scan data\"\"\"\n        self.current_scan = scan_msg\n\n    def odom_callback(self, odom_msg):\n        \"\"\"Update current odometry data\"\"\"\n        self.current_odom = odom_msg\n\n    def validate_navigation_command(self, destination: Point) -> Dict:\n        \"\"\"\n        Validate a navigation command for safety\n        \"\"\"\n        if not self.current_odom:\n            return {\n                'valid': False,\n                'reason': 'No odometry data available',\n                'risk_factors': ['position_unknown']\n            }\n\n        # Check if destination is in forbidden area\n        if self.is_in_forbidden_area(destination):\n            return {\n                'valid': False,\n                'reason': 'Destination is in a forbidden area',\n                'risk_factors': ['forbidden_zone']\n            }\n\n        # Check path for obstacles\n        path_clear, obstacles = self.check_path_for_obstacles(\n            self.current_odom.pose.pose.position,\n            destination\n        )\n\n        if not path_clear:\n            return {\n                'valid': False,\n                'reason': f'Path to destination blocked by obstacles: {obstacles}',\n                'risk_factors': ['obstacle_in_path'],\n                'obstacles': obstacles\n            }\n\n        # Check if destination is too close to walls or obstacles\n        clearance_ok = self.check_destination_clearance(destination)\n        if not clearance_ok:\n            return {\n                'valid': False,\n                'reason': 'Insufficient clearance at destination',\n                'risk_factors': ['insufficient_clearance']\n            }\n\n        # If all checks pass\n        return {\n            'valid': True,\n            'reason': 'Navigation command is safe to execute',\n            'risk_factors': [],\n            'estimated_travel_time': self.estimate_travel_time(destination)\n        }\n\n    def validate_manipulation_command(self, object_position: Point, action: str) -> Dict:\n        \"\"\"\n        Validate a manipulation command for safety\n        \"\"\"\n        if not self.current_odom:\n            return {\n                'valid': False,\n                'reason': 'No position data available',\n                'risk_factors': ['position_unknown']\n            }\n\n        # Check if object is reachable\n        robot_pos = self.current_odom.pose.pose.position\n        distance = self.calculate_distance(robot_pos, object_position)\n\n        max_reach = 1.0  # Maximum reach in meters\n        if distance > max_reach:\n            return {\n                'valid': False,\n                'reason': f'Object is too far away (distance: {distance:.2f}m, max: {max_reach}m)',\n                'risk_factors': ['out_of_reach']\n            }\n\n        # Check if object is at safe height\n        min_height, max_height = self.safety_zones['restricted_heights']\n        if not (min_height <= object_position.z <= max_height):\n            return {\n                'valid': False,\n                'reason': f'Object is at unsafe height (z: {object_position.z:.2f}m, safe range: {min_height}-{max_height}m)',\n                'risk_factors': ['unsafe_height']\n            }\n\n        # Check for obstacles between robot and object\n        path_clear, obstacles = self.check_path_for_obstacles(robot_pos, object_position)\n        if not path_clear:\n            return {\n                'valid': False,\n                'reason': f'Trajectory to object blocked by obstacles: {obstacles}',\n                'risk_factors': ['obstacle_in_trajectory'],\n                'obstacles': obstacles\n            }\n\n        # Validate specific action safety\n        action_valid, action_reason = self.validate_action_specific_safety(action, object_position)\n        if not action_valid:\n            return {\n                'valid': False,\n                'reason': action_reason,\n                'risk_factors': ['action_unsafe']\n            }\n\n        return {\n            'valid': True,\n            'reason': 'Manipulation command is safe to execute',\n            'risk_factors': [],\n            'estimated_execution_time': self.estimate_manipulation_time(action)\n        }\n\n    def is_in_forbidden_area(self, point: Point) -> bool:\n        \"\"\"\n        Check if a point is in a forbidden area\n        \"\"\"\n        # For now, implement a simple circular forbidden zone\n        # In practice, this would check against polygonal regions\n        forbidden_centers = [\n            Point(x=0.0, y=0.0, z=0.0),  # Example: center of room\n            Point(x=5.0, y=5.0, z=0.0)   # Example: specific location\n        ]\n        forbidden_radius = 0.5\n\n        for center in forbidden_centers:\n            distance = self.calculate_distance(point, center)\n            if distance < forbidden_radius:\n                return True\n\n        return False\n\n    def check_path_for_obstacles(self, start: Point, end: Point) -> Tuple[bool, List[Point]]:\n        \"\"\"\n        Check if the path between two points is clear of obstacles\n        \"\"\"\n        if not self.current_scan:\n            return False, []\n\n        # Calculate path points\n        path_points = self.discretize_path(start, end, resolution=0.1)\n        obstacles = []\n\n        for point in path_points:\n            # Check if this point is near an obstacle\n            if self.is_point_near_obstacle(point):\n                obstacles.append(point)\n\n        return len(obstacles) == 0, obstacles\n\n    def discretize_path(self, start: Point, end: Point, resolution: float = 0.1) -> List[Point]:\n        \"\"\"\n        Discretize a path from start to end into points\n        \"\"\"\n        path_points = []\n        distance = self.calculate_distance(start, end)\n        num_points = int(distance / resolution) + 1\n\n        for i in range(num_points + 1):\n            t = i / num_points if num_points > 0 else 0\n            point = Point()\n            point.x = start.x + t * (end.x - start.x)\n            point.y = start.y + t * (end.y - start.y)\n            point.z = start.z + t * (end.z - start.z)\n            path_points.append(point)\n\n        return path_points\n\n    def is_point_near_obstacle(self, point: Point) -> bool:\n        \"\"\"\n        Check if a point is near an obstacle based on laser scan data\n        \"\"\"\n        if not self.current_scan:\n            return True  # Assume obstacle if no data\n\n        # Convert point to robot frame and check against scan\n        # This is a simplified version - in practice, you'd transform coordinates\n        # and check against actual scan beams\n        min_distance = min(self.current_scan.ranges) if self.current_scan.ranges else float('inf')\n        return min_distance < self.robot_radius\n\n    def check_destination_clearance(self, destination: Point) -> bool:\n        \"\"\"\n        Check if there's sufficient clearance at the destination\n        \"\"\"\n        # Check if the destination area is free of obstacles\n        # This would involve checking a small area around the destination\n        # For now, we'll use a simplified check\n        return True\n\n    def validate_action_specific_safety(self, action: str, object_position: Point) -> Tuple[bool, str]:\n        \"\"\"\n        Validate safety for specific manipulation actions\n        \"\"\"\n        if action == 'pick':\n            # Check if object is too heavy or dangerous to pick\n            # This would require object recognition and weight estimation\n            return True, \"Action is safe\"\n\n        elif action == 'place':\n            # Check if placement location is safe\n            return True, \"Action is safe\"\n\n        elif action == 'open':\n            # Check if opening action is safe for this object type\n            return True, \"Action is safe\"\n\n        else:\n            return True, \"Action is safe\"  # Default assumption\n\n    def calculate_distance(self, p1: Point, p2: Point) -> float:\n        \"\"\"\n        Calculate Euclidean distance between two points\n        \"\"\"\n        dx = p2.x - p1.x\n        dy = p2.y - p1.y\n        dz = p2.z - p1.z\n        return (dx*dx + dy*dy + dz*dz)**0.5\n\n    def estimate_travel_time(self, destination: Point) -> float:\n        \"\"\"\n        Estimate travel time to destination\n        \"\"\"\n        if not self.current_odom:\n            return float('inf')\n\n        distance = self.calculate_distance(\n            self.current_odom.pose.pose.position,\n            destination\n        )\n        max_speed = self.safety_zones['speed_limits']['navigation']\n        return distance / max_speed if max_speed > 0 else float('inf')\n\n    def estimate_manipulation_time(self, action: str) -> float:\n        \"\"\"\n        Estimate time for manipulation action\n        \"\"\"\n        # Time estimates for different actions\n        time_estimates = {\n            'pick': 5.0,      # seconds\n            'place': 4.0,     # seconds\n            'open': 6.0,      # seconds\n            'close': 5.0,     # seconds\n            'move': 3.0       # seconds\n        }\n        return time_estimates.get(action, 5.0)\n"})}),"\n",(0,i.jsx)(e.h2,{id:"error-recovery-and-fallback-mechanisms",children:"Error Recovery and Fallback Mechanisms"}),"\n",(0,i.jsx)(e.h3,{id:"command-recovery-strategies",children:"Command Recovery Strategies"}),"\n",(0,i.jsx)(e.p,{children:"Even with robust validation, voice commands may fail during execution. Effective recovery mechanisms are essential:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import time\nfrom enum import Enum\n\nclass RecoveryStrategy(Enum):\n    RETRY = \"retry\"\n    SIMPLIFY = \"simplify\"\n    ALTERNATIVE = \"alternative\"\n    HUMAN_ASSISTANCE = \"human_assistance\"\n    ABORT = \"abort\"\n\nclass VoiceCommandRecovery:\n    def __init__(self, max_retries=3):\n        self.max_retries = max_retries\n        self.failure_history = {}\n        self.known_alternatives = {\n            'kitchen': ['kitchen', 'kit', 'ken', 'chicken'],\n            'bedroom': ['bedroom', 'bed', 'red room'],\n            'living room': ['living room', 'living', 'lounge', 'sitting room'],\n            'bathroom': ['bathroom', 'bath', 'restroom', 'toilet'],\n            'office': ['office', 'study', 'work room']\n        }\n\n    def execute_with_recovery(self, command_parser, command_executor, command_text):\n        \"\"\"\n        Execute a command with built-in recovery mechanisms\n        \"\"\"\n        original_command = command_text\n        retry_count = 0\n        last_error = None\n\n        while retry_count < self.max_retries:\n            try:\n                # Parse the command\n                parsed_command = command_parser.parse_command(command_text)\n\n                # Validate the command\n                if parsed_command['confidence'] < 0.3:\n                    raise ValueError(f\"Command confidence too low: {parsed_command['confidence']}\")\n\n                # Execute the command\n                result = command_executor.execute_command(parsed_command)\n\n                if result['success']:\n                    # Log successful execution\n                    self.log_execution(original_command, command_text, 'SUCCESS', retry_count)\n                    return result\n\n                # If execution failed, determine next action\n                error_msg = result.get('error', 'Unknown execution error')\n                recovery_strategy = self.select_recovery_strategy(error_msg, command_text)\n\n                if recovery_strategy == RecoveryStrategy.RETRY:\n                    retry_count += 1\n                    time.sleep(1)  # Brief pause before retry\n                    continue\n                elif recovery_strategy == RecoveryStrategy.SIMPLIFY:\n                    command_text = self.simplify_command(command_text)\n                    retry_count += 1\n                    continue\n                elif recovery_strategy == RecoveryStrategy.ALTERNATIVE:\n                    alternative_command = self.get_alternative_command(command_text)\n                    if alternative_command and alternative_command != command_text:\n                        command_text = alternative_command\n                        retry_count += 1\n                        continue\n                    else:\n                        break  # No alternative available\n                elif recovery_strategy == RecoveryStrategy.HUMAN_ASSISTANCE:\n                    return self.request_human_assistance(original_command, error_msg)\n                else:  # ABORT\n                    break\n\n            except Exception as e:\n                last_error = str(e)\n                recovery_strategy = self.select_recovery_strategy(str(e), command_text)\n\n                if recovery_strategy == RecoveryStrategy.RETRY:\n                    retry_count += 1\n                    time.sleep(1)\n                    continue\n                elif recovery_strategy == RecoveryStrategy.SIMPLIFY:\n                    command_text = self.simplify_command(command_text)\n                    retry_count += 1\n                    continue\n                elif recovery_strategy == RecoveryStrategy.ALTERNATIVE:\n                    alternative_command = self.get_alternative_command(command_text)\n                    if alternative_command and alternative_command != command_text:\n                        command_text = alternative_command\n                        retry_count += 1\n                        continue\n                    else:\n                        break\n                elif recovery_strategy == RecoveryStrategy.HUMAN_ASSISTANCE:\n                    return self.request_human_assistance(original_command, str(e))\n                else:  # ABORT\n                    break\n\n        # If we've exhausted retries\n        final_result = {\n            'success': False,\n            'original_command': original_command,\n            'attempted_command': command_text,\n            'error': last_error or f\"Command failed after {self.max_retries} attempts\",\n            'attempts_made': retry_count,\n            'recovery_attempts': []\n        }\n\n        self.log_execution(original_command, command_text, 'FAILED', retry_count, last_error)\n        return final_result\n\n    def select_recovery_strategy(self, error_message: str, command_text: str) -> RecoveryStrategy:\n        \"\"\"\n        Select the most appropriate recovery strategy based on error\n        \"\"\"\n        error_lower = error_message.lower()\n\n        # If error suggests misunderstanding of command\n        if any(keyword in error_lower for keyword in ['unknown', 'unrecognized', 'not found', 'invalid']):\n            # Check if it's a location/command that might have alternatives\n            for location, alternatives in self.known_alternatives.items():\n                if any(alt.lower() in command_text.lower() for alt in alternatives):\n                    return RecoveryStrategy.ALTERNATIVE\n\n            # If it's a complex command, try simplifying\n            if len(command_text.split()) > 4:\n                return RecoveryStrategy.SIMPLIFY\n\n            return RecoveryStrategy.RETRY\n\n        # If error suggests physical limitation\n        elif any(keyword in error_lower for keyword in ['obstacle', 'blocked', 'collision', 'reachable']):\n            return RecoveryStrategy.HUMAN_ASSISTANCE\n\n        # If error suggests temporary condition\n        elif any(keyword in error_lower for keyword in ['busy', 'timeout', 'connection', 'offline']):\n            return RecoveryStrategy.RETRY\n\n        # Default to abort for other errors\n        return RecoveryStrategy.ABORT\n\n    def simplify_command(self, command_text: str) -> str:\n        \"\"\"\n        Simplify a complex command to a more basic form\n        \"\"\"\n        original = command_text.lower()\n\n        # Remove qualifiers and modifiers\n        simplified = original.replace('please', '').replace('could you', '').replace('would you', '')\n        simplified = simplified.replace('kindly', '').replace('if you would', '').replace('go ahead and', '')\n\n        # Remove specific descriptors that might be causing issues\n        import re\n        # Remove color descriptors\n        simplified = re.sub(r'\\b(red|blue|green|yellow|black|white|large|small|big|little)\\b\\s*', '', simplified)\n\n        # Remove directional descriptors that might be ambiguous\n        simplified = re.sub(r'\\b(left|right|front|back|near|far|closest|furthest)\\b\\s*', '', simplified)\n\n        # Try to extract the core action\n        if 'go to' in simplified:\n            simplified = 'go to ' + simplified.split('go to', 1)[1].strip()\n        elif 'move to' in simplified:\n            simplified = 'move to ' + simplified.split('move to', 1)[1].strip()\n        elif 'pick up' in simplified:\n            simplified = 'pick ' + simplified.split('pick up', 1)[1].strip()\n        elif 'grab the' in simplified:\n            simplified = 'grab ' + simplified.split('grab the', 1)[1].strip()\n\n        return simplified.strip()\n\n    def get_alternative_command(self, command_text: str) -> str:\n        \"\"\"\n        Get an alternative command that might be clearer\n        \"\"\"\n        # Check against known alternatives\n        for location, alternatives in self.known_alternatives.items():\n            for alt in alternatives:\n                if alt.lower() in command_text.lower():\n                    # Replace with the canonical form\n                    return command_text.lower().replace(alt.lower(), location)\n\n        # If no known alternative, return None\n        return None\n\n    def request_human_assistance(self, original_command: str, error: str) -> Dict:\n        \"\"\"\n        Return a result indicating human assistance is needed\n        \"\"\"\n        return {\n            'success': False,\n            'needs_human_assistance': True,\n            'original_command': original_command,\n            'error': error,\n            'assistance_requested': True,\n            'suggested_actions': [\n                \"Please repeat the command more clearly\",\n                \"Use simpler language\",\n                \"Specify the exact location or object\",\n                \"Check if the robot's path is clear\"\n            ]\n        }\n\n    def log_execution(self, original_command: str, attempted_command: str, status: str,\n                     attempts: int, error: str = None):\n        \"\"\"\n        Log command execution for analysis and improvement\n        \"\"\"\n        log_entry = {\n            'timestamp': time.time(),\n            'original_command': original_command,\n            'attempted_command': attempted_command,\n            'status': status,\n            'attempts': attempts,\n            'error': error,\n            'success': status == 'SUCCESS'\n        }\n\n        # In a real system, you might save this to a database\n        print(f\"Command execution log: {log_entry}\")\n"})}),"\n",(0,i.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,i.jsx)(e.h3,{id:"optimizing-voice-command-processing",children:"Optimizing Voice Command Processing"}),"\n",(0,i.jsx)(e.p,{children:"For real-time robotics applications, optimizing the voice-to-action pipeline is crucial:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import asyncio\nimport concurrent.futures\nfrom functools import lru_cache\nimport threading\nimport time\n\nclass OptimizedVoiceCommandProcessor:\n    def __init__(self):\n        # Use thread pool for CPU-intensive tasks\n        self.thread_pool = concurrent.futures.ThreadPoolExecutor(max_workers=4)\n\n        # Cache for frequently used computations\n        self.command_cache = {}\n        self.max_cache_size = 100\n\n        # Timing statistics\n        self.timing_stats = {\n            'parse_time': [],\n            'validation_time': [],\n            'execution_time': []\n        }\n\n        # Async event loop for non-blocking operations\n        self.loop = asyncio.new_event_loop()\n        threading.Thread(target=self._run_event_loop, args=(self.loop,), daemon=True).start()\n\n    def _run_event_loop(self, loop):\n        \"\"\"Run the asyncio event loop in a separate thread\"\"\"\n        asyncio.set_event_loop(loop)\n        loop.run_forever()\n\n    def process_command_async(self, command_text: str) -> asyncio.Future:\n        \"\"\"\n        Process a command asynchronously\n        \"\"\"\n        future = asyncio.run_coroutine_threadsafe(\n            self._process_command_coroutine(command_text),\n            self.loop\n        )\n        return future\n\n    async def _process_command_coroutine(self, command_text: str) -> Dict:\n        \"\"\"\n        Coroutine for processing commands asynchronously\n        \"\"\"\n        start_time = time.time()\n\n        # Check cache first\n        cached_result = self._check_cache(command_text)\n        if cached_result:\n            return cached_result\n\n        # Parse command\n        parse_start = time.time()\n        parser = VoiceCommandParser()\n        parsed_command = parser.parse_command(command_text)\n        parse_time = time.time() - parse_start\n\n        # Validate command\n        validation_start = time.time()\n        validator = CommandSafetyValidator()\n        validation_result = await self._validate_command_async(validator, parsed_command)\n        validation_time = time.time() - validation_start\n\n        # Store timing\n        self.timing_stats['parse_time'].append(parse_time)\n        self.timing_stats['validation_time'].append(validation_time)\n\n        # Prepare result\n        result = {\n            'command': command_text,\n            'parsed': parsed_command,\n            'validation': validation_result,\n            'processing_time': time.time() - start_time,\n            'cached': False\n        }\n\n        # Add to cache\n        self._add_to_cache(command_text, result)\n\n        return result\n\n    async def _validate_command_async(self, validator, parsed_command: Dict) -> Dict:\n        \"\"\"\n        Validate command using thread pool for CPU-intensive validation\n        \"\"\"\n        def run_validation():\n            command_type = parsed_command['command_type']\n            entities = parsed_command['entities']\n\n            if command_type == 'navigation' and entities.get('location'):\n                # For simplicity, just return a basic validation\n                return {'valid': True, 'reason': 'Validation passed'}\n            elif command_type == 'manipulation' and entities.get('object'):\n                return {'valid': True, 'reason': 'Validation passed'}\n            else:\n                return {'valid': False, 'reason': 'No specific validation rule for command type'}\n\n        # Run validation in thread pool\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(self.thread_pool, run_validation)\n\n    def _check_cache(self, command_text: str) -> Dict:\n        \"\"\"\n        Check if command result is in cache\n        \"\"\"\n        if command_text in self.command_cache:\n            result = self.command_cache[command_text]\n            result['cached'] = True\n            return result\n        return None\n\n    def _add_to_cache(self, command_text: str, result: Dict):\n        \"\"\"\n        Add result to cache with size management\n        \"\"\"\n        if len(self.command_cache) >= self.max_cache_size:\n            # Remove oldest entry (this is a simple FIFO approach)\n            oldest_key = next(iter(self.command_cache))\n            del self.command_cache[oldest_key]\n\n        self.command_cache[command_text] = result\n\n    def get_performance_metrics(self) -> Dict:\n        \"\"\"\n        Get performance metrics for the command processor\n        \"\"\"\n        def safe_average(lst):\n            return sum(lst) / len(lst) if lst else 0\n\n        def safe_max(lst):\n            return max(lst) if lst else 0\n\n        def safe_min(lst):\n            return min(lst) if lst else 0\n\n        return {\n            'parse_time_avg': safe_average(self.timing_stats['parse_time']),\n            'parse_time_min': safe_min(self.timing_stats['parse_time']),\n            'parse_time_max': safe_max(self.timing_stats['parse_time']),\n            'validation_time_avg': safe_average(self.timing_stats['validation_time']),\n            'validation_time_min': safe_min(self.timing_stats['validation_time']),\n            'validation_time_max': safe_max(self.timing_stats['validation_time']),\n            'cache_hit_rate': len([r for r in self.command_cache.values() if r.get('cached')]) / len(self.command_cache) if self.command_cache else 0,\n            'total_processed': len(self.timing_stats['parse_time'])\n        }\n\n    def cleanup(self):\n        \"\"\"\n        Cleanup resources\n        \"\"\"\n        self.thread_pool.shutdown(wait=True)\n        self.loop.call_soon_threadsafe(self.loop.stop)\n"})}),"\n",(0,i.jsx)(e.p,{children:"Voice-to-action command processing represents a critical component of modern robotic systems, enabling intuitive and natural human-robot interaction. By implementing robust parsing, context awareness, safety validation, and recovery mechanisms, we can create voice interfaces that are both powerful and reliable for real-world robotic applications."})]})}function d(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(m,{...n})}):m(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>s,x:()=>r});var i=t(6540);const o={},a=i.createContext(o);function s(n){const e=i.useContext(a);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),i.createElement(a.Provider,{value:e},n.children)}}}]);